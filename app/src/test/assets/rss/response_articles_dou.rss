<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Категория [Статьи] - сообщество программистов</title><link>https://dou.ua/lenta/</link><description>Сообщество программистов</description><atom:link href="https://dou.ua/lenta/articles/feed/" rel="self"></atom:link><language>ru</language><lastBuildDate>Tue, 14 Jan 2020 13:00:03 +0200</lastBuildDate><item><title>Данные важнее, чем модели. Как выглядят эффективные процессы в Data Science</title><link>https://dou.ua/lenta/articles/data-scientists-workflow/</link><description>&lt;p&gt;Всем привет! Меня зовут Вадим, я Machine Learning Researcher в Wix. Работаю в продуктовых компаниях в сфере Data Science уже более шести лет. Занимался построением Machine Learning моделей и закрывал весь цикл Data Science проектов. Мне доводилось строить проекты для разнообразных бизнес-задач, а также в разных доменах ML &amp;amp; Deep Learning.&lt;/p&gt;

&lt;p&gt;Для многих работа дата саентиста выглядит, как черный ящик. Но несмотря на разные задачи, процессы в проектах похожи, равно как и причины возникающих проблем. В этой статье я хочу поделиться своим опытом, рассказать, в чем же именно состоит работа специалиста по Data Science: какие этапы проходит проект, что должен делать дата саентист и как он взаимодействует с другими членами команды.&lt;/p&gt;

&lt;p&gt;Материал будет интересен всем, кто хочет узнать, как выглядит процесс работы дата саентиста. Особенно полезно будет начинающим специалистам и тем, кто хочет перейти в Data Science, так как статья поможет сформировать правильные ожидания от работы.&lt;/p&gt;

&lt;h2&gt;Этапы Data Science проекта&lt;/h2&gt;

&lt;p&gt;В Data Science, как в других IT-направлениях, уже давно есть эффективные процессы структурирования проектов. Удивительно, но далеко не все дата саентисты догадываются об их существовании. Первый фреймворк был придуман в 1996 году и называется CRISP-DM (Cross industry process in data mining). Модной фразы Data Science тогда еще не было, и говорили просто Data Mining. Интересно, что за 24 года своего существования система все ещё актуальна. Появились новые процессы, более подходящие под текущие реалии, но они так или иначе базируются на CRISP-DM. Примером для больших команд может быть процесс &lt;a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview" target="_blank"&gt;Microsoft&lt;/a&gt;, а на &lt;a href="https://towardsdatascience.com/data-science-project-flow-for-startups-282a93d4508d" target="_blank"&gt;Медиуме&lt;/a&gt; есть хорошая инструкция для стартапов.&lt;/p&gt;

&lt;p&gt;Чтобы лучше понять, как же устроена работа дата саентиста, давайте за основу возьмем CRISP-DM и пройдемся по основным этапам этой методологии (я немного изменил оригинальную схему для лучшего воcприятия):&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image3_SqkmFiM.jpg"&gt;&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Определение бизнес-необходимости проекта и установление KPI.&lt;/strong&gt; Обдумать KPI — задача нетривиальная, поэтому над ней зачастую не заморачиваются. Но это может привести к очень неприятным последствиям, вплоть до закрытия проекта.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Работа с данными&lt;/strong&gt;, которые необходимо где-то взять, убедиться в их качестве и подготовить для тренировки. На этом этапе нужно «засучить рукава», забыть о моральном вознаграждении и очень скрупулезно поработать. Интересный факт, что для достижения хороших результатов на этот этап тратится около &lt;a href="https://www.ibm.com/cloud/blog/ibm-data-catalog-data-scientists-productivity" target="_blank"&gt;80% общего времени.&lt;/a&gt; Проверено на личном опыте :) &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Построение модели&lt;/strong&gt;, — наверное, самый приятный этап. Мне кажется, именно из-за него программисты часто хотят перейти в Data Science. Но опытные специалисты знают, что это опасное место, на котором можно зациклиться и потратить много времени зря.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Оценка качества модели&lt;/strong&gt; — самый критичный этап. Во время построения модели мы делаем множество итераций и экспериментов, слабые места есть всегда. От того, как мы их проработаем, зависит скорость развития проекта и его финальное качество.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Вывод в продакшн&lt;/strong&gt; — во многом инженерная часть, но тесно связанная с алгоритмами Machine Learning.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;Правильная коммуникация в команде особенно важна для успеха Data Science проекта. Обычно Data Scientist ведет общение на двух фронтах — с продакт-менеджером и инженером. В маленьких компаниях из-за недостатка людей дата саентисту приходится дополнительно закрывать либо продуктовую, либо инженерную часть. В некоторых компаниях пытаются искать «идеального» специалиста во всех трех сферах, но «быть профессионалом везде = быть профессионалом нигде».&lt;/p&gt;

&lt;p&gt;Давайте подробнее рассмотрим каждый из этапов жизни Data Science проекта.&lt;/p&gt;

&lt;h2&gt;Business understanding&lt;/h2&gt;

&lt;p&gt;Обычно внедрение &lt;nobr&gt;ML-модели&lt;/nobr&gt; инициирует продакт-менеджер. В идеале, ее стоит внедрять в уже готовый проект для улучшения его качества. Если же предлагают использовать Data Science с самого начала и это не является ключевой частью бизнеса, то сперва стоит задать вопрос: а нужен ли он здесь вообще?&lt;/p&gt;

&lt;p&gt;Проект с Data Science требует значительных затрат: как денежных, так временных. Это затраты на получение и обработку данных, проверку гипотез, построение модели, оценку качества, а также решения вопросов интеграции и мониторинга. В самом начале будет гораздо легче и быстрее обойтись без этого. Можно проанализировать рынок, придумать несколько базовых правил и на их основе запустить проект. И только когда этих правил станет слишком много и ими будет тяжело управлять, стоит задуматься об &lt;nobr&gt;ML-алгоритме.&lt;/nobr&gt;&lt;/p&gt;

&lt;p&gt;В чем его польза? Machine Learning алгоритм — это алгоритм, который проанализировал большое количество данных и на основе статистической выборки принимает решение для будущих примеров. Иными словами, на основе статистики алгоритм выбирает наиболее выгодное решение. Это как раз похоже на то, что делают продакт-менеджеры, когда анализируют рынок и составляют правила. Например, «если человек три дня не покупает у нас премиум, то давайте сделаем ему скидку». Просто для этих решений продакт-менеджеры проводят ручной анализ, а машина сделает это автоматически.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image5_NTdjkFG.png" style="width: 300px;"&gt;&lt;/p&gt;

&lt;p&gt;Допустим, что все-таки Data Science проект стоит делать. Первый и важный этап — установить бизнес-метрики для оценки полезности модели. В чем заключается нетривиальность этой задачи? При обучении моделей дата саентисты руководствуются техническими метриками, которые обычно имеют мало общего с бизнес-требованиями. Основная трудность состоит как раз в конверсии технической метрики в бизнесовую и определении KPI, при котором модель можно выводить в продакшн.&lt;/p&gt;

&lt;p&gt;Почему это важно? Для формирования адекватных ожиданий как продакт-менеджера, так и дата саентиста. Продакт-менеджер, для которого моделирование выглядит как black box, не разочаруется из-за своих завышенных ожиданий. Дата саентист, в свою очередь, правильнее расставит приоритеты при оптимизации технических метрик.&lt;/p&gt;

&lt;p&gt;Классический пример: продакт-менеджер хочет знать, кто из пользователей продукта купит премиум-услугу. Техническая метрика для дата саентиста: точность, с которой модель предсказывает покупателей. Однако какая бизнес-цель этой модели? Дать скидку маловероятным покупателям либо оказать дополнительную техподдержку высоковероятным? Где цена ошибки будет выше: перепутать премиума с непремиумом или наоборот? Каждая бизнес-задача имеет свои особенности, и именно под нее стоит составлять бизнес-метрики, которые выражаются в деньгах или конечной полезности.&lt;/p&gt;

&lt;h3&gt;Получение данных&lt;/h3&gt;

&lt;p&gt;Для того чтобы натренировать модель определять взаимосвязи, необходимо иметь размеченные данные. Это набор примеров с характеристиками и «правильный ответ» по каждому из примеров. Например, у вас есть информация по 10к пользователям и о том, что они делали на сайте, а также «ответ»: купили ли они премиум в течение месяца. Другой пример: текст комментария в фейсбуке и оценка его агрессивности от 1 до 10.&lt;/p&gt;

&lt;p&gt;Отмечу, что не для всех задач нужны размеченные данные. Исключение — задачи unsupervised learning (например кластеризация).&lt;/p&gt;

&lt;p&gt;Ключевой фактор результативности модели — качество данных! Если что-то не так с данными, модель выявит неправильные взаимосвязи, и результаты не будут отображать реальность, а полезность будет нулевая. В Data Science кругах ходит популярная фраза: «Garbage in = garbage out». Никакая модель не сможет дать правильное предсказание, если данные на вход были неправильными. Именно поэтому хороший дата саентист проводит гораздо больше времени, разбираясь в данных, нежели тестируя разные модели.&lt;/p&gt;

&lt;p&gt;Сложность получения и подготовки данных напрямую зависит от проекта. А сам процесс может занимать от нескольких дней до нескольких месяцев.&lt;/p&gt;

&lt;p&gt;Ниже рассмотрим основные источники получения размеченных данных.&lt;/p&gt;

&lt;h4&gt;Базы данных (логов) продукта&lt;/h4&gt;

&lt;p&gt;Возможно, это самый простой источник данных, однако и с ним может возникать много трудностей. Допустим, есть проект, на котором необходимо предсказать, когда пользователь перестанет пользоваться продуктом. Для этого необходимы поведенческие данные из логов. Но просто взять и вытащить данные из БД недостаточно. Что может испортить данные? Например:&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;в какой-то период часть ивентов не сохранялась в БД из-за бага;&lt;/li&gt;&lt;li&gt;программисты добавили новую фичу и не покрыли ее логами;&lt;/li&gt;&lt;li&gt;была изменена воронка регистрации, и стало регистрироваться больше пользователей.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Каждый из таких сценариев влияет на данные и, как следствие, влияет на распределения зависимостей для принятия решений. Например, если в продукте ввели новую сокращенную воронку регистрации, то зарегистрируется больше пользователей. Но в результате, процент заинтересованных пользователей будет размываться, и большее количество покинет сайт. Этот факт очень важен для построения модели, потому что профиль среднего пользователя поменялся. Задача дата саентиста как раз сводится к тому, чтобы при моделировании все такие взаимосвязи были отображены в данных.&lt;/p&gt;

&lt;h4&gt;Скрэйпить из интернета&lt;/h4&gt;

&lt;p&gt;Думаю, тут сложность очевидна: вытащить данные из разных источников и унифицировать их. Вдобавок к инженерной сложности соскрейпить данные возникает другая проблема. Часть данных может не иметь никакого отношения к моделированию, и определить и исключить эти данные — достаточно кропотливая работа. Допустим, для задачи необходимо вытащить заголовки текстов с разных сайтов. Как это сделать? Вытаскивать заголовки по тегам &amp;lt;h1&amp;gt;, &amp;lt;h2&amp;gt; недостаточно, потому что пользователь может обойтись без них и просто сделать для обычного текста шрифт побольше. Вытаскивать все тексты со шрифтом больше 32pt тоже нелогично, ведь на сайте может быть весь текст с таким шрифтом. То есть чтобы получить качественные данные, нужно выбирать текст, учитывая особенности каждой отдельной страницы.&lt;/p&gt;

&lt;h4&gt;Ручная разметка&lt;/h4&gt;

&lt;p&gt;Процесс получения таких данных самый долгий и дорогой. Эти данные нужны для задач, с которыми легко справляется человек, но они сложны для алгоритма. К таким сценариям относятся reCAPTCHA, поиск опухолей на МРТ, обведение силуэта автомобиля, оценка эмоции по голосу. Почему такие задачи сложны для алгоритма? Они решаются на так называемых «неструктурированных данных». Например, две картинки с котиками разного цвета и в разном масштабе будут иметь абсолютно разные значения пикселей, хотя они и остаются котиками. Для человека это одна и та же сущность, а алгоритму необходимо будет выяснить, что эти два разных набора пикселей — один и тот же объект.&lt;/p&gt;

&lt;p&gt;При этом автоматически получить размеченные данные для тренировки невозможно. Поэтому для таких задач человек вручную размечает N примеров, а потом эти данные используются для тренировки алгоритма. Задача ручной разметки данных с 2014 года превратилась в отдельную огромную индустрию и продолжает расти. Есть множество компаний, которые занимаются разметкой ваших данных. Например, вы платите компаниям, чтобы они разметили автомобили на ваших видеороликах. &lt;a href="https://www.grandviewresearch.com/industry-analysis/data-annotation-tools-market" target="_blank"&gt;По оценкам&lt;/a&gt; аналитических компаний, в 2018 году рынок аутсорса Data Labelling достиг $318 миллионов, и предсказывают рост до $1,5 миллиарда к 2025. А некоторые эксперты ожидают вдвое больший рост.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image2_JbWJefO.jpg" style="width: 500px;"&gt;&lt;/p&gt;

&lt;p&gt;Подводя итог, могу сказать, что получение данных и их унификация — зачастую трудоемкая задача, которая требует предельного внимания и скрупулезности, а также много времени.&lt;/p&gt;

&lt;h2&gt;Моделирование&lt;/h2&gt;

&lt;p&gt;В чем суть тренировки модели? Если говорить просто: алгоритм — это набор коэффициентов, которые перемножают и суммируют входящие данные. Результирующее число должно быть ответом, который мы ищем. Размеченные данные для тренировки как раз и содержат «желаемый ответ». У нас также есть функция, которая считает «силу ошибки», и по ней мы знаем &lt;em&gt;(спасибо школьным производным),&lt;/em&gt; как надо подправить коэффициенты, чтобы в следующий раз ответ был ближе к правильному. Поэтому, подавая в цикле много примеров, модель корректирует свои веса («обучается»), и будет готова давать предсказания для новых похожих данных.&lt;/p&gt;

&lt;p&gt;К счастью, дата саентисту не нужно придумывать алгоритмы. Уже есть множество различных алгоритмов, которые могут справиться с практически любой задачей. Нам нужно знать их принципы работы и уметь применить уместный, чтобы это не было как «забивать гвозди микроскопом».&lt;/p&gt;

&lt;p&gt;Выбор алгоритма влияет на то, как и какие данные необходимо собирать. Допустим, есть задача отсортировать «объекты» по качеству. Вот два разных способа, как разметить данные, от которых будет кардинально зависеть выбор модели:&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;каждому объекту давать оценку от 1 до 10 и потом усреднить результаты;&lt;/li&gt;&lt;li&gt;показывать объекты попарно и спрашивать, какой лучше.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;В целом, для дата саентиста задача моделирования сводится к следующему:&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;исправить неточности в данных;&lt;/li&gt;&lt;li&gt;добавить новые признаки, чтобы облегчить задачу алгоритму (например, к длине и ширине объекта, добавить «площадь»);&lt;/li&gt;&lt;li&gt;выбрать подходящий алгоритм и параметры тренировки;&lt;/li&gt;&lt;li&gt;натренировать модель;&lt;/li&gt;&lt;li&gt;разобраться, в каких ситуациях модель допускает ошибки;&lt;/li&gt;&lt;li&gt;повторять до готовности.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Анализ ошибок модели — критический этап для успеха &lt;nobr&gt;ML-проекта.&lt;/nobr&gt; Качественный анализ и классификация ошибок дает возможность определить корень проблемы. Часто проблема находится в данных: баг при препроцессинге, недостаточно данных, взаимосвязи в данных слишком сложны для модели. Причин может быть много.&lt;/p&gt;

&lt;p&gt;Лучшая стратегия при моделировании — двигаться итерациями. Сперва стоит построить полный pipeline: от получения данных до конечного результата для клиента. При этом важно закрыть этот pipeline в самую первую очередь, и желательно, чтобы он был максимально простым с самой простой моделью. Дальше итеративно улучшаем его, каждый раз принимая решения, анализируя ошибки. Условно процесс должен выглядеть так:&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image6_k1JUfMc.jpg" style="width: 400px;"&gt; &lt;/p&gt;

&lt;p&gt;Почему важно начать с самой простой модели? Чем проще модель, тем обычно она лучше объясняет, где были допущены ошибки, и благодаря этому гораздо легче определять, на чем фокусироваться дальше. Такому принципу следуют все крупные компании уровня Google, Amazon и Facebook. У Гугла есть на эту тему очень хорошие &lt;a href="https://developers.google.com/machine-learning/guides/rules-of-ml" target="_blank"&gt;гайдлайны&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Один из грехов дата саентистов — потратить мало времени на анализ ошибок и вместо этого долго играться с параметрами модели. Потом пытаться применить более сложный алгоритм или построить ансамбль из алгоритмов, чтобы «усреднить» их предсказания. В итоге итерации сводятся к такому виду, как на рисунке. Упускается важный факт, что чаще всего ошибка в данных, ведь модель просто проецирует распределение данных. Если ошибка в данных, то будет ошибка и в предсказаниях. Двигаясь по такому циклу, хороших результатов можно и не получить в принципе.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image1_txDUeiS.jpg" style="width: 400px;"&gt; &lt;/p&gt;

&lt;p&gt;При достижении каких-либо интересных результатов либо наоборот, когда прогресса нет, стоит обсудить статус модели с продакт-менеджером.&lt;/p&gt;

&lt;h2&gt;Оценка результативности и принятие решения&lt;/h2&gt;

&lt;p&gt;Обсуждая результаты модели с продакт-менеджером, важно понимать, что ответственность за выведение &lt;nobr&gt;ML-модели&lt;/nobr&gt; в продакшн лежит именно на нем, и он должен быть уверен в качестве и предсказуемости результатов. Поэтому правильно объяснить результаты и принципы работы модели крайне важно. К тому же ошибки предсказаний, которые допускает модель и которые допустил бы человек, значительно отличаются. И вот когда продакт-менеджер видит ошибки, допущенные моделью, они кажутся ему нелепыми. А если он не понимает, почему так произошло, возникает недоверие к модели. Однако, когда человеку удается осознать, почему так произошло, эффект «загадки» пропадает, и барьер недоверия уменьшается.&lt;/p&gt;

&lt;p&gt;По своему опыту обратил внимание, что коммуникация результатов очень подвержена такому когнитивному искажению, как &lt;a href="https://ru.wikipedia.org/wiki/%D0%93%D0%B0%D0%BB%D0%BE-%D1%8D%D1%84%D1%84%D0%B5%D0%BA%D1%82" target="_blank"&gt;Halo effect&lt;/a&gt;. (&lt;em&gt;Из Википедии: результат воздействия общего впечатления о чём-либо на восприятие частных особенностей. Примером может служить впечатление, что у людей с привлекательной внешностью большие умственные способности.)&lt;/em&gt; Он работает как в позитивную, так и в негативную сторону. В связи с этим обсуждение текущих результатов модели создает определенную эмоциональную окраску для будущих оценок. Это влияет на принятие конечного решения. И даже если все ваши решения data driven, из-за неправильного донесения особенностей выход модели в продакшн может изрядно замедлиться (например, в середине проекта решают ужесточить ранее установленный KPI).&lt;/p&gt;

&lt;p&gt;Другой интересный аспект — не все ошибки модели можно уловить с помощью метрик. И рекомендации продакт-менеджера по улучшению могут быть ценным источником информации. Яркий пример: в рекомендательных системах алгоритм зацикливается на одной-двух отраслях и рекомендует только их, что ведет к недостаточному разнообразию. Продакт-менеджер, который хорошо знает особенности продукта, поможет определить похожие вещи, в то время как дата саентист может упустить важность этой метрики и не оценить по ней качество модели.&lt;/p&gt;

&lt;p&gt;Бывает, что качества модели недостаточно, чтобы выводить ее в продакшн. При этом нет четкого понимания, какие действия наверняка улучшат качество. Такая ситуация вероятна, так как Data Science проекты не имеют четко определенного пути к цели. Задача сводится к пониманию проблемы, составлению гипотез и разнообразным экспериментам. Причины неуспеха могут быть связаны как со сложностью задачи, так и с качеством и количеством данных. Умение признать нерешаемость задачи и найти достойный pivot — очень ценный навык. Хороший пример pivot`a от сложной к более простой задаче: не делать полноценную систему рекомендаций, а внутри каждой категории рекомендовать самый популярный продукт.&lt;/p&gt;

&lt;h2&gt;Выведение в продакшн&lt;/h2&gt;

&lt;p&gt;Многие менеджеры ожидают, что дата саентист сможет самостоятельно задеплоить модель в продакшн. Для некоторых несложных проектов это может быть вполне разумной задачей. Однако, чем сложнее проект и чем выше цена ошибки — тем критичнее участие инженера. Вот несколько причин, почему инженер может быть ключевым звеном для успешности Data Science проекта.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Данные для тренировки модели и для продакшна различаются. &lt;/strong&gt;Это обычная ситуация. Например, для тренировки дата саентист брал данные из аналитической базы, а для продакшна нужны реал-тайм. В аналитической базе данные часто собираются из разных источников и проходят какую-то трансформацию. Соответственно, для продакшн-данных будет другой процесс подготовки и агрегации разных источников. Другой пример: для тренировки и оценки качества данные собираются в batch. Однако в продакшне данные могут приходить по одному, поэтому задача оптимизации и распараллеливания вычислений будет выглядеть совсем по-другому.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Оптимизация кода.&lt;/strong&gt; Во время рисерча дата саентист обычно пишет «грязный» и неэффективный код. И это абсолютно нормальная ситуация, потому что построение модели — это экспериментальный и итеративный процесс. Дата саентист тестирует много идей, многие из них не срабатывают, поэтому большое количество кода меняется и удаляется. Каждый раз писать качественный код — большая трата времени. И только к моменту, когда модель дошла до статуса готовности выхода в продакшн, есть смысл оптимизировать код. Ускорение вполне может достигать &lt;nobr&gt;10-100 раз.&lt;/nobr&gt; И это хорошее место для вовлечения инженера.&lt;/p&gt;

&lt;p&gt;Например, в Python есть библиотека Pandas, которая позволяет очень удобно манипулировать данными, но она работает медленно. На критических проектах в продакшне мы эту библиотеку выпиливаем полностью, однако без этой библиотеки на проверку гипотез мы бы тратили в несколько раз больше времени.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Автоматизация.&lt;/strong&gt; Обновление моделей — часто болезненный этап для проекта. Сценариев для обновления обычно два — устаревание модели и выход новой версии:&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Устаревание модели&lt;/strong&gt;. Для некоторых проектов это естественная ситуация, так как меняется продукт, поведение пользователей, данные. Если модель привязана к «текущему состоянию проекта» — то для того, чтобы она еще долго оставалась полезной, ее нужно обязательно обновлять. Перетренировку модели на актуальных данных, сравнение качества и выливание в продакшн можно и желательно автоматизировать. Это можно делать и вручную, но тратить на это время — не очень эффективная стратегия.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Выход новой версии.&lt;/strong&gt; Когда дата саентист приходит с новой версией модели, обычно, кроме самой модели, меняется и процесс обработки данных. А это ведет к необходимости дополнительной оптимизации, а также проверки эффективности по качеству и скорости. У нас на проекте был интересный use case с нейронной сетью, где на одном из этапов мы уменьшаем разрешение картинки. Для продакшна мы заменили библиотеку для преподготовки изображения с PIL на OpenCV. И вот одна и та же функция с одним и тем же названием bicubic_interpolation давала разницу примерно в ~7%. Несложно догадаться, что это значительно повлияло на качество :) Так что тесты и мониторинг — это правильный уровень maturity Data Science проекта. &lt;em&gt;(&lt;/em&gt;&lt;a href="https://guerrilla-analytics.net/2018/01/13/joel-test-of-data-science-maturity/" target="_blank"&gt;&lt;em&gt;По ссылке&lt;/em&gt;&lt;/a&gt;&lt;em&gt; хороший набор критериев для оценки уровня развитости вашего Data Science проекта.)&lt;/em&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image4_dur1NP3.png" style="width: 600px;"&gt; &lt;/p&gt;

&lt;p&gt;Идеальный вариант обновления модели — через А/Б тест, когда одновременно крутится две версии, чтобы удостовериться, что все корректно работает. Такой вариант не всегда возможен, поэтому чаще идут более простым путем. Собирают небольшой набор тестовых данных, которые ни одна из моделей не видела и которые не использовались для оптимизации. Эти данные служат только для финальной проверки: действительно ли новая модель работает лучше.&lt;/p&gt;

&lt;h2&gt;Итоги&lt;/h2&gt;

&lt;p&gt;В Data Science проектах так же, как и других Software проектах, сложились свои, проверенные временем процессы. Если им следовать, шансы на успех значительно повышаются.&lt;/p&gt;

&lt;p&gt;Ключевые идеи:&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Важно понимать целесообразность использования Machine Learning для решения задачи.&lt;/li&gt;&lt;li&gt;Установление правильных бизнес-требований — ключ к успешному проекту.&lt;/li&gt;&lt;li&gt;Главная сложность и залог успеха — в получении качественных данных.&lt;/li&gt;&lt;li&gt;Данные гораздо важнее, чем модель!&lt;/li&gt;&lt;li&gt;Процесс моделирования состоит из проверки гипотез, и вполне вероятно, что ни одна из них не сработает.&lt;/li&gt;&lt;li&gt;Деплоймент модели в продакшн — отдельный и значимый этап, который требует дополнительной автоматизации и другого подхода к данным.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Спасибо за ваше время!&lt;/p&gt;

&lt;h4&gt;Интересные ссылки&lt;/h4&gt;

&lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview" target="_blank"&gt;Microsoft Data Science Process&lt;/a&gt;;&lt;/li&gt;&lt;li&gt;&lt;a href="https://towardsdatascience.com/data-science-project-flow-for-startups-282a93d4508d" target="_blank"&gt;Data Science Flow for Startups&lt;/a&gt;;&lt;/li&gt;&lt;li&gt;&lt;a href="https://developers.google.com/machine-learning/guides/rules-of-ml" target="_blank"&gt;Google ML Recommendations&lt;/a&gt;;&lt;/li&gt;&lt;li&gt;&lt;a href="https://guerrilla-analytics.net/2018/01/13/joel-test-of-data-science-maturity/" target="_blank"&gt;Joel’s Test for Data Science&lt;/a&gt;;&lt;/li&gt;&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" target="_blank"&gt;CRISP-DM&lt;/a&gt;.&lt;a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" target="_blank"&gt; &lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Vadym Boikov</dc:creator><pubDate>Tue, 14 Jan 2020 13:00:03 +0200</pubDate><guid>https://dou.ua/lenta/articles/data-scientists-workflow/</guid></item><item><title>Веб-розробка: вчора, сьогодні, завтра</title><link>https://dou.ua/lenta/articles/web-development-status-2020/</link><description>&lt;p&gt;Привіт, мене звуть В’ячеслав Колдовський, я &lt;a href="https://t.me/programmingmentor" target="_blank"&gt;Programming Mentor&lt;/a&gt;. У веб-розробці я з &lt;nobr&gt;1990-х,&lt;/nobr&gt; тепер працюю в SoftServe над навчальними проектами. Чверть століття я спостерігав за еволюцією вебу, бачив появу та смерть технологій, робив ставки в конкурентних війнах, мене завжди цікавило, куди воно все рухається, — саме про це хочу з вами поговорити, і розмова не буде короткою.&lt;/p&gt;

&lt;p&gt;Історія часто цинічно жартує з людськими винаходами: далеко не завжди задумане ставало реальністю, дуже часто реальністю ставало те, що задуманим не було. Схоже, вся історія вебу й відповідно веб-розробки — те, із чого воно все починалося, як розвивалося, куди направлялося й де опинилося тепер, — яскравий приклад цього твердження.&lt;/p&gt;

&lt;p&gt;Перший веб-сайт побачив світ 6 серпня 1991 року. Це був набір примітивних веб-сторінок, які, власне, і презентували всесвітню павутину — World Wide Web. Цікаво, що він і &lt;a href="http://info.cern.ch/hypertext/WWW/TheProject.html" target="_blank"&gt;досі доступний&lt;/a&gt; за тією самою адресою, що й майже три десятиліття тому.&lt;/p&gt;

&lt;p&gt;Якщо ви перейдете на той сайт і заглянете в його код, то вас може спіткати когнітивний дисонанс: попри те, що сайт відкривається і відображається цілком нормально на сучасних браузерах, його код лише віддалено нагадує той, який ми пишемо сьогодні. Саме в цьому полягають краса й біль веб-розробки — потреба створювати рішення, що мають такий самий вигляд і працюють незмінно в умовах середовища та інструментів, стабільність яких лише в тому, що вони постійно змінюються. Сьогодні вже виросло не одне покоління розробників, які не задумуються про те, що Інтернет як мережа існувала задовго до презентації WWW, веб мав стати всього-на-всього одним із сервісів, які вона надавала. Навряд чи хтось міг подумати під час запуску, на що він перетвориться, — власне, у цьому і є корінь проблем, про які ми поговоримо далі.&lt;/p&gt;

&lt;h2&gt;HTML&lt;/h2&gt;

&lt;p&gt;Як сам батько вебу — фізик-контрактор CERN Тім Бернерс-Лі — його уявляв, можна побачити на тому самому першому сайті: «The WorldWideWeb (W3) is a wide-area hypermedia information retrieval initiative aiming to give universal access to a large universe of documents». У вільному перекладі звучить так: це така собі бібліотека документів, пов’язаних між собою гіперпосиланнями. Тобто мовиться про всього-на-всього документи, які подані у форматі гіпертексту та поєднані між собою гіперпосиланнями. Ключові терміни тут: «документи», «гіпертекст» та «гіперпосилання».&lt;/p&gt;

&lt;p&gt;Цікаво, що Тім Бернерс-Лі не був автором ні ідеї, ні самого терміна «гіпертекст». Термін винайшов ще 1963 року Тед Нельсон, який працював над проектом Xanadu — спробою переосмислити поняття документа й роботою з інформацією взагалі. Xanadu — це проект усього життя Теда Нельсона, а його ідеї випередили час. Але як нерідко трапляється в реальному світі, успішним стає не оригінальний автор науково обґрунтованої рафінованої ідеї, що часто відірвана від реальності, а той, хто побачив, як поєднати ідею з реальністю, навіть пожертвувавши якимись її важливими принципами. Тут можна згадати класичний випадок, коли автор ООП Алан Кей жорстко розкритикував C++ як невдалу імплементацію його задумів: &lt;a href="https://en.wikiquote.org/wiki/Alan_Kay" target="_blank"&gt;«Коли я винайшов ООП, то не мав на увазі C++»&lt;/a&gt;. Те саме можна сказати й про винахід Теда Нельсона — йому не надто сподобалося, як його ідеї були зреалізовані у WWW. Ось &lt;a href="https://youtu.be/En_2T7KH6RA" target="_blank"&gt;цікаве відео&lt;/a&gt; з 2008 року, де автор демонструє робочий прототип і пояснює ключові концепції свого проекту. Там на власні очі можна переконатися: воно дуже відрізняється від того, що зреалізував Тім Бернерс-Лі.&lt;/p&gt;

&lt;p&gt;Крім концепції гіпертексту та гіперпосилань, варта уваги й імплементація веб-сторінок за допомогою HTML. Усі веб-розробники знають про сучасну п’яту версію HTML, але мало кому відомо, що першою формальною версією цієї мови є HTML 2.0, яка вийшла у форматі RFC аж у листопаді 1995 року. До того моменту як такого стандарту мови взагалі не було. Тім Бернерс-Лі запозичив ідею мови в SGML, але водночас досить вільно інтерпретував її, а тому веб-сторінки не були коректними SGML-документами, хоча й використовували синтаксичні конструкції мови, такі як теги та атрибути. Утім, версії HTML із другої по четверту будувалися як SGML-документи, однак уже в HTML5 від такої ідеї відмовилися. Для охочих залишається можливість зреалізувати веб-сторінки у форматі XHTML, але сенсу в тому небагато, бо виникають деякі побічні ефекти, наприклад селектори CSS стають чутливими до реєстру тощо. Історія показала, що ідея підтягнути HTML відповідно до SGML із самого початку була нелогічною, — схоже, треба вміти вчасно відрубати кінці минулих ідей і не тягти із собою в майбутнє ворох минулого — веб у цьому сенсі гарний антиприклад.&lt;/p&gt;

&lt;p&gt;Якщо говорити про веб-сторінки загалом і HTML зокрема, то варто зазначити, що формат сам по собі є не чим іншим, як формою представлення інформації у вигляді структурованого документа, що може містити текст, інформацію у вигляді списків і таблиць, зображення, аудіо та відео, а також, звісно, гіперпосилання. Усе це призначено лише для того, щоб показати інформацію користувачу, ще й у досить статичній формі, подібно до сторінки книжки, газети чи журналу. Інтерактивність в HTML зреалізована за допомогою елементів форми, завдання яких — «узяти» інформацію в користувача й відправити її на сервер.&lt;/p&gt;

&lt;p&gt;Якщо ж говорити про використання HTML як UI для аплікацій, то вона для цього мало пристосована, і, наприклад, будь-який звичний для UI елемент у формі табів та прив’язаних до них блоків сторінки просто відсутній у HTML. Те саме стосується «карусельки» з елементів чи відомого всім бургер-меню — звісно, їх усі можна зреалізувати, але не тільки засобами чистого HTML, що вкотре доводить: мова для цього не була задумана. Особливо цікаво, що таких елементів у чистому HTML немає дотепер, хоча й трапляються вони мало не на кожному сучасному сайті. Для дружнього до UI середовища було б логічним мати можливість програмно «намалювати» щось на екрані — досить дати координати й усе. Однак це не зовсім легко, бо не можна просто так узяти й намалювати щось поверх інших тегів сторінки, ми обмежені DOM-деревом і не можемо малювати «просто на сторінці», необхідно використати canvas, спозиціювати його тощо.&lt;/p&gt;

&lt;h2&gt;CSS&lt;/h2&gt;

&lt;p&gt;Думаю, досить про HTML, поговорімо про CSS. Скільки болю доводилося бачити в очах цих молодих людей, що з ентузіазмом починали вивчати веб-розробку, з легкістю опановували основи HTML, а потім обривали свій політ, зіткнувшись із суворою реальністю роботи з таким чудовим винаходом, як каскадні таблиці стилів.&lt;/p&gt;

&lt;p&gt;Вважається, що автором CSS є норвежець Гокон Лі (Håkon Wium Lie), який запропонував ідею Тімові Бернерс-Лі в жовтні 1994 року, а перша версія стандарту вийшла два роки після того. До CSS як такого поділу на представлення і контент в HTML не існувало, і ідею розділити обов’язки можна було б вважати геніальною, якби вона не була одним з фундаментальних принципів розробки програмних проектів. Але, як ми знаємо, зло ховається в деталях, і найбільше це стосується CSS. Іронічно, що &lt;a href="https://www.wiumlie.no/en" target="_blank"&gt;сайт винахідника CSS&lt;/a&gt; не дуже добре виглядає ні на занадто широких, ні на вузьких екранах, і навіть валідатор CSS має до нього претензії.&lt;/p&gt;

&lt;p&gt;Можливо, і не варто було аж так прискіпуватися, але на те є серйозна причина: попри купу різноманітної функціональності в CSS, підтримки цілісного й продуманого підходу до розміщення елементів на сторінці довго не існувало, і робилося це комбінацією якихось трюків та хаків, зрозуміти які непідготовленій людині було вкрай нетривіально, взяти хоча б використання властивості float, яка задумувалася для роботи із зображеннями, однак на тривалий час стала опорою для адаптивної верстки. Згодом float уступила своє місце Flexible Layout, який насправді, незважаючи на всю свою гнучкість, теж не зовсім призначений для повноцінної верстки складних макетів, і лише з Grid Layout, що з’явився зовсім недавно, усе більш-менш стало на свої місця.&lt;/p&gt;

&lt;p&gt;Написання коду на чистому CSS приносить мало задоволення, особливо тому, що в ньому практично відсутні були механізми реалізації одного з найважливіших принципів розробки — DRY (Do Not Repeat Yourself). Донедавна змінних не існувало, для вкладених елементів DOM доводиться повторювати ланцюжки селекторів, а можливості перевикористовувати код, модифікуючи його поведінку залежно від певних умов, немає й тепер.&lt;/p&gt;

&lt;p&gt;Саме тому досвідчені розробники рідко виявляють бажання мати справу з чистим CSS, і натомість використовують препроцесори, тобто переходять на метамову, що, своєю чергою, має певні наслідки — від потреби в компіляції до ускладнення відладки, через те що реальний код, який виконується браузером, часто суттєво відрізняється від того, який написаний в IDE.&lt;/p&gt;

&lt;p&gt;Узагалі CSS — такий потужний і гнучкий інструмент, що його часто застосовують не за призначенням, скажімо, виправляючи хиби HTML. Наприклад, у HTML є тег, який дозволяє зробити горизонтальну лінію, логічно було б мати тег, який робить вертикальну. Однак такого немає, і щоб намалювати вертикальну, доводиться креативити, багато хто робить це по-різному і використовує CSS. Водночас особливо цинічний випадок такого застосування — це трансформувати елемент горизонтальної лінії в лінію вертикальну. «Цинічний» — бо якщо сприймати код HTML семантично, то тег hr, що має створювати горизонтальну лінію, повинен створювати саме горизонтальну лінію. (Якщо говорити про семантично коректний підхід до того, як розв’язати це завдання, то тут ліпше створити власний елемент в HTML, стандарт це дозволяє, &lt;a href="https://stackoverflow.com/a/31707873" target="_blank"&gt;ось приклад&lt;/a&gt;).&lt;/p&gt;

&lt;h2&gt;JavaScript&lt;/h2&gt;

&lt;p&gt;Переходячи до, ймовірно, найцікавішої складової фронтенду, варто зробити відступ і запитати: а що робить мова програмування на фронтенді взагалі? Тут варто зазначити, що в &lt;nobr&gt;1990-х&lt;/nobr&gt; людину, яка займалася веб-сайтом, дуже часто називали веб-майстер, і далеко не завжди це була людина з навичками програмування. Якось на цю тему пожартував Кріс Коєр, засновник css-tricks&lt;span&gt;.&lt;/span&gt;com: &lt;a href="https://css-tricks.com/the-great-divide/" target="_blank"&gt;«Два фронтенд-розробники сидять поруч у барі. Їм ні про що говорити»&lt;/a&gt;. І це не той випадок, коли хтось пише на React, а інший на Angular. Це радше про те, що один типовий програміст — з алгоритмічним мисленням, якому зручніше згенерувати весь контент динамічно та імперативно, досить лише отримати контейнер, а другий, навпаки, людина, для якої ближчою є семантика елементів, структура контенту, стилі, анімації тощо, тобто декларативний підхід. Якщо говорити про філософію, закладену в HTML, то саме другий підхід є коректнішим, хоч би як дивно це здавалося для декого з розробників сьогодні.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image1_wSN23Aq.png" width="600"&gt; &lt;small&gt;&lt;em&gt;&lt;a href="https://css-tricks.com/the-great-divide/" target="_blank"&gt;Джерело&lt;/a&gt;&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Власне, сам Тім Бернерс-Лі жодної мови програмування всередині браузера не передбачав, тому не дивно, що історія її виникнення скидається на детектив. Компанія Netscape, заснована у квітні &lt;nobr&gt;1994-го,&lt;/nobr&gt; випустила першу публічну версію браузера Netscape Navigator з номером 0.9 у листопаді того самого року. Браузер стрімко почав набирати популярність, і вже за чотири місяці займав три чверті всього ринку.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image3_mzYueKX.png" width="600"&gt; &lt;small&gt;&lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Netscape_Navigator" target="_blank"&gt;Частка ринку браузера Netscape Navigator, &lt;nobr&gt;1994–2007&lt;/nobr&gt;&lt;/a&gt;&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Засновник компанії Марк Андрессен вирішив, що HTML не вистачає саме легковагової скриптової мови програмування, код якої можна було б писати прямо в тексті веб-сторінок. Тож у квітні 1995 року він найняв Брендона Айка, який був тоді відомим фахівцем з мов програмування, для того щоб вбудувати мову програмування Scheme у браузер Netscape Navigator. Однак у мови Scheme досить специфічний синтаксис, а Sun тоді мала сильні ринкові позиції та активно просувала Java, тому однією з вимог, які висунув Брендон Айк до нової мови, була синтаксична подібність з Java. До вимог також належало, щоб мова була досить проста та не містила класів, тож для Брендона вона стала своєрідним челенджем — він вирішив зреалізувати в ній ООП, але без класів.&lt;/p&gt;

&lt;p&gt;У Netscape прийнято було працювати дуже швидко, тому Брендон Айк розробив прототип мови за 10 робочих днів у травні 1995 року. Це справді дуже мало для того, щоб створити власну мову програмування з нуля, але, схоже, цілком досить, якщо базуватися на вже готових рішеннях. Саме тому нова мова запозичила синтаксис із Java, основну функціональність із Scheme, а реалізацію ООП із Self.&lt;/p&gt;

&lt;p&gt;Також цікавою особливістю мови була вбудована стійкість до помилок — синтаксичних і помилок під час виконання коду; це давало б змогу користуватися нею непрофесійним розробникам. Тому, наприклад, у JS крапка з комою для поділу тверджень є опційною, а арифметичні операції взагалі не переривають хід виконання коду — можна сміливо ділити на нуль чи добувати квадратний корінь з від’ємного числа; спроба прочитати значення з масиву за його межами просто поверне undefined, а якщо забути задекларувати змінну і присвоїти раніше незадекларованому ідентифікатору якесь значення, то помилки не виникне, змінна створиться автоматично, однак це навряд чи добре, бо створена змінна буде не на рівні блоку чи функції, а в глобальному просторі імен.&lt;/p&gt;

&lt;p&gt;На той момент така гнучкість і стійкість до помилок у коді здавалася важливим досягненням, що залучало б до програмування людей, які до того не мають стосунку. Але час показав, що для професійних розробників, які звикли до строгості й точності в програмуванні, JavaScript здавалася недосить серйозною мовою. Тим більше що деякі рішення були здійснені під тиском обмеженого часу, і навіть сам автор мови визнав їх невдалими. Наприклад, якось 2013 року через твітер у Брендона Айка запитали про дивне рішення стосовно відсутності блочної області видимості в JavaScript, на що він відповів, що 10 днів не вистачило на блочну область видимості, та й на той час для простої скриптової мови такий підхід здавався цілком прийнятним.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image2_Fk0k4Mo.png"&gt; &lt;small&gt;&lt;em&gt;Діалог у твітері з Брендоном Айком стосовно блочної області видимості&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Годі було 1995 року уявити, що одного дня JavaScript стане найпопулярнішою мовою програмування у світі. Власне, тоді, у &lt;nobr&gt;1990-х,&lt;/nobr&gt; старт JS серед розробників навряд чи можна було вважати вдалим, бо ця мова сприймалася як щось недосить серйозне, чим слід користуватися, коли треба замінити зображення, поверх якого рухається курсор миші, чи якесь інше схоже завдання.&lt;/p&gt;

&lt;p&gt;Варто згадати про тогочасний тренд — уникати написання коду на фронтенді загалом і використовувати інструменти, що дають змогу конструювати сторінки візуально, а код генерувати автоматично. Серед таких інструментів — Vermeer FrontPage, що вийшов 1995 року (пізніше Microsoft FrontPage) та Macromedia Dreamweaver (пізніше Adobe Dreamweaver), який вийшов &lt;nobr&gt;1997-го.&lt;/nobr&gt; Можливість згенерувати код веб-сторінки з візуального її представлення отримав Adobe Photoshop. Тобто дуже часто фронтенд-частина сайту сприймалася як частина проекту, з якою працюють дизайнери — не програмісти, бо для останніх є бекенд.&lt;/p&gt;

&lt;p&gt;До речі, програмування на бекенд прийшло значно раніше, ніж на фронтенд, там його місце здавалося логічнішим. Першою такою технологією, що давала змогу динамічно генерувати HTML, була технологія CGI (Common Gateway Interface), створена &lt;nobr&gt;1993-го,&lt;/nobr&gt; всього за два роки після запуску першого сайту. Зреалізована вона була дуже примітивно: HTTP-запит від клієнта направлявся на скрипт на сервері, який отримував параметри запиту та генерував відповідь, направивши її на стандартний вивід, що, власне, і отримував браузер у відповідь. CGI дозволяла писати код будь-якою мовою, досить було запустити її на сервері — хоч Perl, хоч C, однак загалом це робилося доволі трудомістко.&lt;/p&gt;

&lt;p&gt;Справжнім проривом у веб-розробці стала поява PHP 1995 року — ця мова спеціально була створена для вебу й давала змогу органічно поєднати HTML та синтаксично близьку до C мову програмування. Ідея виявилася напрочуд вдалою і послугувала прообразом для Active Server Pages від Microsoft, що вийшла &lt;nobr&gt;1996-го,&lt;/nobr&gt; та багатьох інших технологій, які зайняли свою нішу ринку, проте не змогли наблизитися до популярності PHP навіть чверть століття після того.&lt;/p&gt;

&lt;p&gt;Певною мірою своїм успіхом PHP завдячує тому, що браузер тоді не сприймався як серйозна платформа для програмування. Можливості JavaScript у роботі зі сторінкою були дуже обмежені, до того ж у другій половині &lt;nobr&gt;1990-х&lt;/nobr&gt; розгорілися браузерні війни: Microsoft випустила свій браузер, у якому імплементувала власну інтерпретацію JavaScript під назвою JScript, і особливо проблемно було створювати кросбраузерний код.&lt;/p&gt;

&lt;p&gt;Ось, наприклад, фрагмент коду з реального сайту 1998 року. Можна лише уявити, яке «задоволення» приносило писати щось таке:&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image5_BPkOjua.png"&gt; &lt;small&gt;&lt;em&gt;Саме такий вигляд мав кросбраузерний код 1998 року&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;h2&gt;RIA&lt;/h2&gt;

&lt;p&gt;Як додаткове підтвердження того, що пара HTML/JavaScript не сприймалася як платформа для розробки, слід назвати появу та розквіт різноманітних плагінів, які мали бути вбудованими у веб-сторінки — чи взагалі заміняти їх — і надавати розробникам «повноцінніший» досвід програмування. Зокрема, 1996 року Sun у межах платформи Java випустила Java Applets, а Microsoft представила ActiveX, водночас компанія Macromedia придбала FutureWave Software і випустила свій плагін для браузера — Macromedia Flash, який спочатку позиціювався як медіапрогравач, але згодом став повноцінною програмною платформою.&lt;/p&gt;

&lt;p&gt;Усі ці плагіни були сторонніми для вебу, потребували часу на завантаження та інсталяцію й не приносили особливого задоволення користувачам браузерів. Водночас можливості для програмування в браузерах саме за допомогою JavaScript розвивалися досить повільно, хоча й були перші зрушення. Зокрема, коли в Netscape відчули серйозну загрозу з боку Microsoft, то вирішили віддати JavaScript на стандартизацію в організацію Ecma International. Організація досить оперативно взялася стандартизувати та розвивати мову й упродовж &lt;nobr&gt;1997–1999&lt;/nobr&gt; років випустила три версії EcmaScript. Також 1997 року світ побачив Microsoft Internet Explorer 4.0 — нищівний для Netscape продукт, завдяки якому MS перемогла в браузерних війнах. Серед його особливостей була задекларована підтримка Dynamic HTML — набір технологій, до яких входили JavaScript та DOM, що нарешті давали змогу повноцінно маніпулювати вмістом HTML-сторінки на клієнтському боці й навіть динамічно застосовувати стилі.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image4_iRC2bTq.png" width="600"&gt; &lt;small&gt;&lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Usage_share_of_web_browsers#/media/File:Browser_Wars_(en).svg" target="_blank"&gt;Браузерні війни &lt;nobr&gt;1996–2009&lt;/nobr&gt;&lt;/a&gt;&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Утім, розробники браузерів та плагінів об’єднали зусилля й запропонували 2002 року концепцію RIA — Rich Internet Applications, у яких ідея користуватися браузерами з плагінами подавалася як необхідність для того, щоб отримувати якісний медіаконтент та досвід роботи із сайтом загалом. Такий підхід значною мірою нівелював ідею вебу як єдиної платформи обміну інформації, бо Flash, Silverlight тощо — це, по суті, окремі незалежні платформи, контрольовані комерційними організаціями, які самостійно визначають правила гри.&lt;/p&gt;

&lt;h2&gt;Web 2.0 / Web.3.0&lt;/h2&gt;

&lt;p&gt;Уже наприкінці &lt;nobr&gt;1990-х&lt;/nobr&gt; стало зрозуміло, що Інтернет загалом та веб зокрема захопили світ, потіснивши всі інші мережі й способи представлення інтерактивної інформації. У січні 1999 року вийшла &lt;a href="http://darcyd.com/fragmented_future.pdf" target="_blank"&gt;стаття&lt;/a&gt; авторства Дарсі Дінуччі, у якій уперше прозвучало про концепцію Web 2.0, авторка назвала наявний на той час веб лише ембріоном того, що має прийти в майбутньому. Основною рисою Web 2.0 була робота на пристроях з різними обчислювальними можливостями, розмірами екранів, способами введення інформації та в умовах кардинально різної швидкості зв’язку. Упродовж кількох років концепцію Web 2.0 доповнило поняття «контент», генероване користувачами, хоча тоді мало хто уявляв, яким воно стане в недалекому майбутньому з тотальним засиллям соціальних мереж. Тоді це здавалося радше як набір незалежних сайтів-блогів, на сторінках яких відвідувачі могли б залишати коментарі.&lt;/p&gt;

&lt;p&gt;Як бачимо, концепція Web 2.0 виявилася пророчою, бо тепер веб дуже подібний до того образу, який створили два десятиліття тому.&lt;/p&gt;

&lt;p&gt;Однак батько вебу Тім Бернерс-Лі дещо по-іншому хотів би бачити його майбутнє, тож зосередив свої зусилля на так званому семантичному вебі, назвавши його &lt;a href="https://en.wikipedia.org/wiki/Semantic_Web#Web_3.0" target="_blank"&gt;Web 3.0&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Мета семантичного вебу — дати можливість машинам розуміти дані, які описує HTML. Досягнути її можна, використовуючи такі технології, як RDF (Resource Description Framework) та OWL (Web Ontology Language).&lt;/p&gt;

&lt;p&gt;Семантичний веб дає змогу описати схему даних, які представлені в HTML-коді, і в ідеалі мав би надати можливість машинам читати дані так, як це роблять люди.&lt;/p&gt;

&lt;p&gt;Наприклад, звичайний елемент div, що містить інформацію про людину, доповнений RDF-атрибутами, може мати такий вигляд:&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image7_zicZBo0.png" width="600"&gt; &lt;small&gt;&lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Semantic_Web#Example" target="_blank"&gt;Семантична розмітка&lt;/a&gt;&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;У браузері відвідувачі сайту бачитимуть звичайний текст, а машини, наприклад пошукові системи, зможуть отримати структуровану інформацію.&lt;br&gt;Попри те, що семантичний веб набув певного поширення, важко стверджувати, що це стало трендом чи буде ним у найближчому майбутньому. Причин можна назвати багато, однак одна з них — це ігнорування веб-розробниками семантичної розмітки, що, своєю чергою, позбавляє сенсу подальші зусилля в напрямку використання семантичних даних у веб-сторінках. Виходить своєрідне замкнене коло, і, попри разючу поширеність вебу та обсяг інформації в ньому, інформація значною мірою досі неструктурована, — отже, поки що навряд чи можна сказати, що мрія батьків-засновників про таку собі всесвітню бібліотеку структурованих знань здійснилася.&lt;/p&gt;

&lt;h2&gt;AJAX&lt;/h2&gt;

&lt;p&gt;Незважаючи на появу DHTML, у фронтенд-програмуванні тривалий час була одна фундаментальна проблема: класична модель комунікації браузер-сервера передбачає надсилання чи отримання даних із сервера разом із запитом, який направляє браузер лише в момент переходу чи оновлення сторінки (або фрейму, що фактично є незалежною сторінкою). Це означає, що можливості отримати чи надіслати дані, не оновивши водночас сторінку, з моменту створення вебу не існувало.&lt;/p&gt;

&lt;p&gt;Однак 1999 року разом із браузером MS IE версії 5.0 Microsoft випустила оновлену версію ActiveX бібліотеки MSXML, однією з особливостей якої була підтримка можливості без перезавантаження сторінки та асинхронно, не блокуючи потоку виконання JavaScript-коду, надіслати запит на сервер, отримати результат і за допомогою DHTML вбудувати його в сторінку.&lt;/p&gt;

&lt;p&gt;Цікаво, що кілька років таку можливість не помічали: хоча її і використовували на певних сайтах, але загалом про масове поширення не йшлося доти, поки Google не запустила у &lt;nobr&gt;2004-му&lt;/nobr&gt; сервіс Google Suggest, що показав можливості технології всьому світу. У лютому 2005 року Джеймс Ґаррет опублікував статтю &lt;a href="https://en.wikipedia.org/wiki/Ajax_(programming)#cite_note-garrett-1" target="_blank"&gt;«AJAX: новий підхід до побудови веб-аплікацій»&lt;/a&gt;, у якій було запропоновано сам термін та детально описано технологію, що й зумовило активне її застосування.&lt;/p&gt;

&lt;p&gt;AJAX фактично був останнім фрагментом у тому пазлі технологій, які перетворювали рідні компоненти вебу — HTML, CSS та JavaScript — на повноцінну платформу програмування.&lt;/p&gt;

&lt;h2&gt;jQuery&lt;/h2&gt;

&lt;p&gt;З появою AJAX інтерес до програмування за допомогою JavaScript у браузері суттєво зріс, однак писати кросбраузерний код не стало простіше навіть за умов монополії браузера від Microsoft, оскільки додалися проблеми сумісності різних версій IE.&lt;/p&gt;

&lt;p&gt;2006 року світ побачила перша версія бібліотеки jQuery, яку розробив Джон Резіґ, що надихнувся ідеєю вибору елементів HTML за допомогою селекторів CSS в іншої бібліотеки cssQuery, але вдало поєднав її зі зручними методами маніпуляції DOM та вбудував можливість робити AJAX-запити.&lt;/p&gt;

&lt;p&gt;Для багатьох розробників, які випробовували свої сили в браузерному програмуванні, jQuery стала саме тою рятівною соломинкою, що дозволяла вибратися з трясини кросбраузерного програмування та сфокусуватися на самому завданні, а не способах його розв’язання. Інтерес до «рідного» програмування в браузері, а не до сторонніх плагінів почав суттєво зростати.&lt;/p&gt;

&lt;h2&gt;HTML5 / EcmaScript 2015&lt;/h2&gt;

&lt;p&gt;У січні 2008 року вперше побачила світ чернетка нової, п’ятої версії HTML. Крім власне модифікації самої мови розмітки, вона містила також опис значної кількості API, що перетворювали браузер на повноцінну платформу програмування. Якщо говорити власне про мову розмітки, то серед важливих змін варто назвати появу семантичних тегів і відмову від деяких тегів, що відповідали за представлення. Вихід HTML5 як стандарту затягнувся на цілих шість років. Утім, як розробники самих браузерів, так і веб-розробники сприйняли його дуже позитивно, адже нарешті він перетворював браузер на повноцінну програмну платформу, нівелюючи потребу в такому сторонньому для вебу створінні, як плагіни для RIA.&lt;/p&gt;

&lt;p&gt;Паралельно з роботою над HTML5 велася робота й над черговою версією JavaScript. 2009 року виходить EcmaScript 5, рівно через 10 років після попередньої версії. На диво, змін за десятиліття було запропоновано відносно небагато, незважаючи на те що вже почали відчуватися ті хиби мови, які були закладені під час її створення. Лише через шість років світ побачив по-справжньому оновлений стандарт мови під назвою EcmaScript 2015, і разом з ним мова нарешті позбулася деяких дитячих хвороб, які її переслідували (наприклад, уже згадана раніше блочна область видимості), а також отримала оновлений синтаксис, зберігаючи водночас зворотну сумісність з ES5.&lt;/p&gt;

&lt;p&gt;Саме парочку HTML5 / ES2015 варто вважати переходом веб-платформи в період зрілості, потреба в jQuery суттєво зменшилася, програмувати на чистому JS стало значно комфортніше.&lt;/p&gt;

&lt;p&gt;Шлях стандартизації HTML5 був непростим, тривалий час існувало два окремі стандарти: від W3C та WHATWG, і лише 2019 року двом організаціям вдалося домовитися про єдиний стандарт — тепер це просто &lt;a href="https://html.spec.whatwg.org/multipage/" target="_blank"&gt;HTML Living Standard&lt;/a&gt; без номерів версій, над яким оригінально працювала WHATWG. У стандартизації EcmaScript також відбулися важливі зміни: нова версія стандарту мови тепер виходить щороку, мова розвивається динамічніше й водночас зміни не навантажують розробників великими порціями.&lt;/p&gt;

&lt;h2&gt;SPA&lt;/h2&gt;

&lt;p&gt;Уже наприкінці першої декади &lt;nobr&gt;2000-х&lt;/nobr&gt; стало помітно, що обсяг коду на фронтенді дуже зріс, важливою стає модульність і підтримуваність рішень, jQuery в цьому аспекті мало що могла запропонувати, тому на сцену почали виходити фреймворки Single Page Application, які самою можливістю свого існування мають завдячувати AJAX.&lt;/p&gt;

&lt;p&gt;Knockout, Backbone, ExtJS, AngularJS — далеко не повний перелік SPA-фреймворків, які почали тоді з’являтися й здебільшого використовували патерн MVC або його похідні. Сам патерн винайшли ще наприкінці &lt;nobr&gt;1970-х,&lt;/nobr&gt; але у веб-розробці його використання стало особливо поширеним. Вважається, що вперше MVC у вебі застосували 1996 року в маловідомому на сьогодні серверному фреймворку WebObjects, потім він швидко поширився на інші серверні фреймворки й загалом дуже комфортно почувався у вебі, накладаючись на традиційну модель комунікацій, яка передбачала перезавантаження сторінки під час кожного запиту клієнта.&lt;/p&gt;

&lt;p&gt;Однак з появою AJAX гармонія MVC почала руйнуватися, бо, крім традиційних запитів на контролер, які мають оновити представлення, з’явилися запити, які не зовсім вкладаються в патерн. І саме за допомогою SPA цю гармонію вдалося відновити. Також у пригоді став створений на початку двотисячних Дуґласом Крокфордом формат передачі даних JSON — значно зручніший за XML. За десять років SPA розквітли й закріпилися на фронтенді, практично монополізувавши його як підхід до створення веб-рішень. Багато веб-розробників навіть не бачили альтернатив і не задумувалися про них, та й узагалі навряд чи запитували себе, чи потрібно щось інше, ніж SPA.&lt;/p&gt;

&lt;p&gt;Справді, з погляду класичних розробників, для яких важливі принципи розподілу обов’язків, модульності та структурування рішень, патернів і всього того, що навчає сучасна інженерія програмного забезпечення, SPA — це дуже гарне рішення для побудови проектів. Однак якщо поглянути на це з погляду філософії та духу вебу й запитати, що зі SPA не так, то відповідь буде дуже проста: усе не так!&lt;/p&gt;

&lt;p&gt;Спочатку така відповідь може збентежити, але якщо задуматися, то складно не погодитися з тим, що Single Page — це не дуже добре, оскільки в самій природі вебу закладено мати багато сторінок, щоб з’єднати їх гіперпосиланнями. І ці сторінки не мають бути просто імітацією в браузері, вони мають бути доступні будь-якому клієнту, який робить HTTP-запит до сервера за конкретною адресою, а не лише тому, який отримає мініміфікований код на JavaScript, виконає його та імперативно збудує сторінку — у такому разі ми втрачаємо декларативну сутність вебу, підміняючи його аплікаціями. Власне, тут і стає зрозумілим, що Application теж зайва — хіба ми не визначилися з тим, що HTML значно ближче до книжки чи журналу, ніж до графічного інтерфейсу комп’ютерних аплікацій?&lt;/p&gt;

&lt;p&gt;Слід визнати, хоч би як це було прикро сучасним розробникам, які не уявляють фронтенд без SPA, що ця концепція насправді чужа для вебу, бо намагається підмінити ідеї, закладені у веб, підходами, що прийшли з розробки аплікацій з графічним інтерфейсом користувача. Хтось, можливо, вважатиме, що це не принципово, і якщо воно працює, то яка різниця, як саме воно зроблено. Але практика показує, що це не так. Усе-таки SPA виконуються в браузері, і щонайменше залишається потреба мати можливість робити посилання на окремі сторінки. Для цього почали реалізовувати deep linking, перенаправляючи будь-які запити на бекенд на одну сторінку, що є точкою входу в аплікацію, і виводячи потрібну сторінку на фронтенді. Але потім стало зрозуміло, що не можна цілком відмовитись від декларативного HTML на фронтенді й повністю підмінити його динамічною аплікацією, ліпше мати HTML-контент на сервері, як наслідок — виникло поняття Server-Side Rendering. Однак, реалізуючи SSR, виникає завдання передати стан із сервера до клієнта, це теж потребує певних зусиль на реалізацію. Також не дуже тривіальною виявляється підтримка доступності (accessibility) для SPA-аплікацій, декларативний HTML для цього ліпше пристосований. І так далі — скидається на безперервний процес, у якому розв’язання одних проблем призводить до появи інших.&lt;/p&gt;

&lt;p&gt;Загалом складність розробки і супроводу SPA для вебу починає виходити за розумні межі, дедалі складніше переконувати клієнтів у тому, що цьому підходу немає альтернатив. І чи це справді так?&lt;/p&gt;

&lt;h2&gt;А що в нас із фреймворками?&lt;/h2&gt;

&lt;p&gt;JavaScript-фреймворки — то завжди гаряча тема. Ми всі прекрасно знаємо: день минає даремно, якщо світ не побачив новий фреймворк. Хоча це чи не найулюбленіша тема для новачків похоліварити, досвідчені розробники рідко піддаються на провокації та просто спостерігають за трендами й вивчають те, на що є попит.&lt;/p&gt;

&lt;p&gt;Приблизно у &lt;nobr&gt;2014-му&lt;/nobr&gt; AngularJS був лідером серед SPA-фреймворків, але відтоді багато що змінилося. Уже кілька років поспіль в абсолютних лідерах React, який формально є більше бібліотекою, ніж фреймворком. Проте популярність — це річ оманлива: по-перше, вона перемінна, постійно тримати корону вдається хіба що jQuery, по-друге, не завжди найпопулярніша технологія є найоплачуванішою — тут варто згадати про PHP.&lt;/p&gt;

&lt;p&gt;Багато хто вже «поховав» Angular, але тут не все так просто: у Google переписали AngularJS з нуля, навіть ім’я змінили, повністю поламавши зворотну сумісність, проте навряд чи хтось скаже, що цим вони зробили гірше. Як наслідок — вийшов такий собі мегаконструктор SPA, який не дуже підходить для нескладних проектів, але вдало знайшов свою нішу в корпоративних. Він і далі активно розвивається, Google забезпечує серйозну підтримку — загалом майбутнє видається значно оптимістичнішим, ніж може здатися на перший погляд.&lt;/p&gt;

&lt;p&gt;Упродовж кількох останніх років досить упевнено почувається VueJS. Легковаговість і простота — це два основні чинники, які забезпечують його популярність. Він активно розвивається й особливо популярним став в Азії — власне це, ймовірно, і варто зарахувати до нечисленних недоліків: часто значно простіше отримати підтримку китайською мовою, ніж англійською.&lt;/p&gt;

&lt;p&gt;Але справжнє відкриття 2019 року, яке ще має себе показати у &lt;nobr&gt;2020-му, —&lt;/nobr&gt; це «фреймворк, що щезає» — Svelte. Поки React та Vue називають Virtual DOM своїми перевагами, Svelte, навпаки, серед переваг називає його відсутність. Але ключова його особливість полягає в тому, що після збірки аплікації в ній не залишається фреймворку як такого — аплікація компілюється в чистий JS, за допомогою якого і відбуваються маніпуляції з елементами сторінки. Це досить суттєво відрізняє Svelte від інших, хоча такий підхід використали розробники Angular в останніх версіях із новим двигуном рендерингу Ivy.&lt;/p&gt;

&lt;p&gt;Наприкінці 2019 року серед фронтенд-розробників всього світу проводилося традиційне опитування «State of JS», у якому за рівнем цікавості Svelte посів перше місце.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image6_5ewrGaO.png" width="800"&gt; &lt;small&gt;&lt;em&gt;&lt;a href="https://2019.stateofjs.com/front-end-frameworks/" target="_blank"&gt;Рейтинг фреймворків за рівнем цікавості 2019 року&lt;/a&gt;&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Загалом підхід, використаний у Svelte, можна лише вітати: замість того щоб укотре в браузері будувати мета-платформу, розробники фреймворку використали можливості браузера. Тут доречно згадати, що розвиток браузерів як платформи теж не стоїть на місці, і серед останніх нововведень особливої уваги варта підтримка WebComponents — механізму, що дає змогу створювати власні елементи в HTML, які мають незалежні стилі й логіку, розв’язуючи ті самі завдання, що більшість фронтенд-фреймворків. Тож варто очікувати поширення саме такого підходу, що наближає фреймворки до браузера як платформи, а не віддаляється від нього.&lt;/p&gt;

&lt;h2&gt;Що з бекендом?&lt;/h2&gt;

&lt;p&gt;Ще з &lt;nobr&gt;1990-х&lt;/nobr&gt; на бекенді заправляє балом стек LAMP і похідні, створені за його образом та подобою. І питання навіть не в конкретному наборі технологій, які його формують, а в загальних принципах роботи — запити з фронтенду обслуговуються динамічно, у процесі залучена база даних та сервер аплікацій, що відносно повільно працюють та складно масштабуються по горизонталі. У такому підході принципово нічого не змінилося навіть з приходом SPA, які дозволили відмовитися від передачі згенерованих сторінок із сервера, переганяючи лише дані за допомогою RESTful API.&lt;/p&gt;

&lt;p&gt;Водночас варто зазначити, що розробникам на бекенді доводиться розв’язувати типові завдання навіть у різних проектах — зреалізовувати аутентифікацію та авторизацію, створювати типові CRUD-операції для сутностей предметної ділянки, передавати DTO між різними рівнями аплікації, покривати все це тестами тощо. Щоб не повторюватися щоразу й перевикористовувати зроблені раніше рішення, ще з кінця &lt;nobr&gt;1990-х&lt;/nobr&gt; стали набирати популярність CMS (Content Management Systems), а з поширенням RESTful API — так звані Headless CMS, що взагалі не мають фронтенду.&lt;/p&gt;

&lt;p&gt;Попри те, що CMS вдається розв’язати певну частину проблем з перевикористанням коду, проблеми з розгортанням та підтримкою серверів залишаються. Подальша еволюція таких рішень — це міграція в хмари і використання сервісів, які повністю керуються хмарними провайдерами. У цьому сенсі дуже привабливими видаються рішення, такі як Google Firebase та подібні. Поєднання можливостей аутентифікації, авторизації, API для роботи зі структурованими даними з можливостями хостингу з підтримкою CDN — серйозний аргумент проти того, щоб займатися всіма цими питаннями самостійно. Поділ монолітів на мікросервіси та використання платформ, які беруть на себе масштабування під навантаженням, — такі архітектурні рішення спонукають використовувати хмарні сервіси й не займатися питаннями керування та підтримки інфраструктури.&lt;/p&gt;

&lt;p&gt;Одна з цікавих інновацій на бекенді, що швидко набуває популярності й здатна вплинути на прийняті підходи до розробки рішень, — це &lt;a href="https://en.wikipedia.org/wiki/GraphQL" target="_blank"&gt;GraphQL&lt;/a&gt;, розроблена у Facebook технологія, що дозволяє на фронтенді сформувати запит до структури даних, які має повернути бекенд. Такий підхід позбавляє бекенд-розробників потреби створювати нескінченні CRUD-операції та загалом є гарною альтернативою до RESTful API.&lt;/p&gt;

&lt;p&gt;Як наслідок — дедалі активніше спостерігається тенденція використовувати можливості CDN, щоб розміщувати статичний контент веб-рішень максимально близько до клієнта, а динамічну частину веб-рішення будувати так, щоб вона адаптувалася до рівня навантажень, використовуючи для цього можливості платформ хмарних провайдерів, а не просто переносячи в хмари монолітні аплікації в незмінному вигляді.&lt;/p&gt;

&lt;h2&gt;JAMstack&lt;/h2&gt;

&lt;p&gt;Наприкінці 2017 року вийшла цікава &lt;a href="https://thenewstack.io/the-sweetness-of-jamstack-javascript-apis-and-markup/" target="_blank"&gt;стаття&lt;/a&gt;, у якій досить детально було описано стек технологій під загальною назвою JAMstack (JavaScript + API + Markup). Сам термін винайшла та активно просуває компанія Netlify, яка дуже вдало почала просувати ідею альтернативного до SPA підходу, що насправді зовсім не новий, але значно ближчий до оригінальних ідей вебу, ніж SPA.&lt;/p&gt;

&lt;p&gt;JAMstack пропагує ідею так званих статичних сайтів, хоча термін «статичний» тут зовсім недоречний, бо насправді статичними ці сайти не є, просто, на відміну від SPA, їхній звичайний стан — це заздалегідь відрендерений статичний HTML-контент, розміщений на CDN, і динамічні вставки лише там, де треба. Бекенд розглядається у вигляді набору API, до яких можна звертатися за допомогою JavaScript, і це далеко не завжди кастомний бекенд, це можуть бути вже готові сервіси, які реалізують аутентифікацію, сервіси збереження даних і таке інше. Текстовий контент не обов’язково тримати у вигляді HTML, для цього доцільно застосувати якусь із мов розмітки, наприклад Markdown. А сам сайт оновлюється за допомогою процесів CI/CD, які стартують за тригером, наприклад після оновлення коду в системі контролю версій.&lt;/p&gt;

&lt;p&gt;Оскільки статичний контент може бути на CDN максимально близько до клієнта, а також не потребує часу на динамічний рендеринг, то сайти, створені за допомогою JAMstack, — надзвичайно швидкі. Для індексації пошуковими системами та deep linking немає потреби в якихось додаткових діях — це спрощує і в кінцевому підсумку здешевлює розробку.&lt;/p&gt;

&lt;p&gt;Імовірно, JAMstack не підійде до всіх можливих сайтів, однак цілком придатний до великої кількості поширених категорій, таких як блоги, сайти новин і навіть онлайн-магазини. На відміну від SPA, JAMstack ідеологічно значно ближчий оригінальним ідеям вебу: контент не відтворюється імперативно за допомогою JavaScript, а представлений декларативно в сторінках, розміщених на сервері, хоча можливість робити динамічні ставки є, зокрема можна відмовитися від переходу між сторінками за допомогою браузера й робити це в стилі SPA.&lt;/p&gt;

&lt;p&gt;GatsbyJS — один з найвдаліших фреймворків для JAMstack, на DOU навіть є &lt;a href="https://dou.ua/lenta/articles/gatsbyjs-guide/" target="_blank"&gt;цикл публікацій&lt;/a&gt; про нього, він поєднує в собі підтримку React, GraphQL, Markdown і досить гнучкий, щоб адаптуватися до різних сценаріїв використання.&lt;/p&gt;

&lt;p&gt;Цікаво, що деякі компоненти JAMstack не новинка, однак вдале їх поєднання та врахування специфіки вебу, схоже, і є тим каталізатором, що має забезпечити успіх нового стеку.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image8_aN488zI.png" width="800"&gt; &lt;small&gt;&lt;em&gt;&lt;a href="https://medium.com/memory-leak/the-jamstack-its-pretty-sweet-e0834e4e6bb7" target="_blank"&gt;JAMstack формують добре відомі складники&lt;/a&gt;&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;h2&gt;WebAssembly&lt;/h2&gt;

&lt;p&gt;Одна з технологій, вплив на веб-розробку якої непросто передбачити, — це WebAssembly. Можна сказати, що це скринька Пандори для альтернативних до JavaScript мов програмування в браузері. Якби її підтримка з’явилася ще років десять тому, то в JavaScript було б значно менше шансів у битві проти інших, «серйозніших» мов програмування. Однак тепер я розцінюю шанси як рівні, до того ж сам роблю ставку на JavaScript, бо ця мова суттєво оновилася упродовж кількох останніх років, а її застосування для вебу настільки природне, наскільки звично розробнику писати ідентифікатори англійською мовою.&lt;/p&gt;

&lt;p&gt;Оскільки серед основних аргументів на користь WebAssembly називають швидкість, то ми, ймовірно, спостерігатимемо процес, коли десь там «під капотом» у реєстрі npm оновлюватимуться бібліотеки, які будуть оптимізовуватися за швидкістю з використанням альтернативних до JavaScript мов, однак їхні інтерфейси так само залишатимуться на JavaScript.&lt;/p&gt;

&lt;p&gt;Звісно, WebAssembly поступово почне «відкушувати» частину розробників у JavaScript, цьому сприятимуть такі проекти, як, наприклад, &lt;a href="https://en.wikipedia.org/wiki/Blazor" target="_blank"&gt;Microsoft Blazor&lt;/a&gt;, призначені здійснити давню мрію бекенд-розробників: позбавити себе задоволення вивчати JS. Проте ці процеси навряд чи відбуватимуться швидко, і якщо говорити про перспективу кількох найближчих років, то монополії JavaScript на фронтенді це навряд чи суттєво загрожуватиме.&lt;/p&gt;

&lt;p&gt;Імовірно, єдина мова, яка в найближчій перспективі хоч якось помітно здатна потіснити JavaScript у вебі, — це TypeScript, але її навряд чи можна назвати альтернативою до JS, це радше такий собі «JavaScript наступного рівня». Він опційний для використання і стає потрібен тоді, коли проект значно розростається. Тож важливо мати не лише статичну типізацію, а й інтерфейси, декоратори та інші складові, які є в TS.&lt;/p&gt;

&lt;h2&gt;Висновок&lt;/h2&gt;

&lt;p&gt;Ця тема така розлога, що про неї можна видати цілу книжку, але рано чи пізно розмову варто завершувати. Історія вебу особливо цікава тим, що вона не стояла на місці: тут завжди все активно розвивається, щось бурлить і вибухає, дещо шумно приходить, а потім непомітно зникає. Враховуючи роль вебу у світовому бізнесі, нічого немає дивного в тому, що він був, є і, поза сумнівом, буде в майбутньому полем битви великих корпорацій за свій вплив на звичайних користувачів і розробників.&lt;/p&gt;

&lt;p&gt;У цій боротьбі завжди з’являється хтось, хто відчуває в собі сили та бажання підім’яти під себе веб, встановивши монополію на браузер чи певні технології, які мають використовувати розробники. Спочатку це була Netscape, потім її витіснила Microsoft, згодом у вебі почала панувати Google, яку, своєю чергою, витісняє Facebook. Але втримувати корону ще складніше, ніж її одержати, бо сила вебу — у відкритості стандартів, і щоразу, коли його намагаються монополізувати чи інфікувати сторонніми складниками, — як, наприклад, було з RIA, — він знаходить сили оновитися й позбутися їх. Але веб не робить це самостійно — це роблять розробники, що своїми руками сьогодні надають йому тих форм, які він матиме завтра. І щоб розробляти під веб, треба розуміти його, треба відчувати його філософію, ідеї, які заклали в нього його творці. Саме тому я закликаю розробників відповідальніше ставитися до тих рішень, які ми ухвалюємо, і підходів, які ми застосовуємо, старатися менше використовувати сторонніх для вебу речей, а більше того, що нам він дає як платформа, бо, як казав геніальний Алан Кей, «немає найліпшого способу передбачити майбутнє, ніж створити його».&lt;/p&gt;

&lt;p&gt;Контакти автора: &lt;a href="https://www.linkedin.com/in/koldovsky/" target="_blank"&gt;LinkedIn&lt;/a&gt;, &lt;a href="https://t.me/programmingmentor" target="_blank"&gt;телеграм-канал&lt;/a&gt;, &lt;a href="http://programmingmentor.com.ua/" target="_blank"&gt;веб-сайт&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">В&amp;#39;ячеслав Колдовський</dc:creator><pubDate>Tue, 14 Jan 2020 10:00:03 +0200</pubDate><guid>https://dou.ua/lenta/articles/web-development-status-2020/</guid></item><item><title>Секретные техники проработки требований. Часть 3</title><link>https://dou.ua/lenta/articles/techniques-for-developing-requirements-3/</link><description>&lt;p&gt;В предыдущих статьях (&lt;a href="https://dou.ua/lenta/articles/techniques-for-developing-requirements-1/" target="_blank"&gt;1&lt;/a&gt;, &lt;a href="https://dou.ua/lenta/articles/techniques-for-developing-requirements-2/" target="_blank"&gt;2&lt;/a&gt;) мы с вами рассмотрели большую часть техник, которые я использую на практике, чтобы проверить требования на полноту. В данной статье я хотел бы рассмотреть оставшиеся три техники:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Администрирование.&lt;/li&gt;&lt;li&gt;Отчетность.&lt;/li&gt;&lt;li&gt;Нефункциональные требования.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Не знаю почему, но бизнес-аналитики больше всего не любят прорабатывать именно требования к администрированию, отчетности и нефункциональные требования. И в то же время без проработки вышеупомянутых требований будущая система не будет полноценно работоспособна. &lt;/p&gt;

&lt;h2&gt;Администрирование&lt;/h2&gt;

&lt;p&gt;Как-то мне на глаза попался подписанный договор на разработку системы, и в дополнение к договору были прикреплены требования. В требованиях я вообще не увидел упоминания об управлении справочниками и учетными записями. И на мой резонный вопрос: «А где?» — мне ответили что-то в стиле: «Потом допилим, мол, договор уже подписан и бюджет согласован». Пытался возразить, что потом будут проблемы и что, по моему мнению, могут быть подводные камни. Руководителем проекта мои доводы были зафиксированы как риски и успешно забыты. &lt;/p&gt;

&lt;p&gt;Прошло полгода, и когда «сдавали» систему, представители заказчика спросили: «А как нам управлять справочными данными?» Дело в том, что один из основных справочников системы имел более 10 000 записей (вот вам и подводный камешек). А обновление данных должно было происходить не реже чем один раз в час. Также необходимо было реализовать синхронизацию данных пользователей системы из active directory. &lt;/p&gt;

&lt;p&gt;От представителей информационной безопасности прозвучал очень интересный вопрос об управлении учетными записями в системе, а также журналировании действий пользователей (а вот это — целый булыжник, о который споткнулась наша лодка...).&lt;/p&gt;

&lt;p&gt;После долгих разбирательств, переговоров и доработок систему запустили спустя семь месяцев. Да, частично трудозатраты были покрыты заказчиком, но потери времени и нервов можно было избежать еще до старта проекта.&lt;/p&gt;

&lt;p&gt;Как показывает мой личный опыт, для успешного функционирования системы необходимо иметь возможность:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;управлять справочниками системы;&lt;/li&gt;&lt;li&gt;управлять учетными записями, ролями и полномочиями;&lt;/li&gt;&lt;li&gt;архивировать и восстанавливать объекты;&lt;/li&gt;&lt;li&gt;журналировать действия пользователей.&lt;/li&gt;&lt;/ul&gt;

&lt;h3&gt;Управление справочниками системы&lt;/h3&gt;

&lt;p&gt;При проработке требований к справочникам нужно сразу задаться вопросом об источнике данных. Если справочник не планируется сопровождать пользователями системы, соответственно, должен быть проработан и описан способ получения данных из источника. &lt;/p&gt;

&lt;p&gt;В некоторых случаях ваша будущая система может содержать данные, которые необходимы для других систем. В этом случае ваша система будет источником для других систем, и необходимо проработать, какие данные мы должны предоставлять другим системам и каким способом мы будем предоставлять данные. По моему опыту, два самых распространенных способа — это обмен файлами через сервисные шины и иногда при помощи программного интерфейса &lt;a href="https://ru.wikipedia.org/wiki/API" target="_blank"&gt;API&lt;/a&gt; использование dblink. Определить оптимальный способ обмена информацией вам поможет технический специалист или архитектор. &lt;/p&gt;

&lt;p&gt;Пример описания атрибутов я приводил &lt;a href="https://dou.ua/lenta/articles/techniques-for-developing-requirements-2/" target="_blank"&gt;во второй части статьи&lt;/a&gt; в разделе «Объектно-ориентированная модель», данный подход использую и для описания атрибутов для обмена. &lt;/p&gt;

&lt;p&gt;В случае управления справочными данными напрямую пользователями системы, как правило, прорабатываю прототипы пользовательского интерфейса, опираясь на технику CRUD, которую также уже описывал ранее во второй части статьи. &lt;/p&gt;

&lt;h3&gt;Управление учетными записями, ролями и полномочиями&lt;/h3&gt;

&lt;p&gt;При описании требований к системе и ролевой модели следует помнить, что нужен интерфейс, при помощи которого будут выполняться операции по администрированию пользователей. &lt;/p&gt;

&lt;p&gt;При проработке администрирования пользователей следует задаваться вопросами:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Каким образом пользователь будет зарегистрирован в системе?&lt;/li&gt;&lt;li&gt;Какая информация о пользователе должна храниться в системе?&lt;/li&gt;&lt;li&gt;Как назначить роль и полномочия пользователю?&lt;/li&gt;&lt;li&gt;Какие дополнительные возможности необходимо предусмотреть (поиск по списку пользователей, фильтрация, блокировка пользователя, смена пароля, редактирование данных, удаление)?&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Есть и системы, которые для авторизации пользователями используют другие системы или приложения. В моей практике больше всего для этого использовалось Active Directory, а полномочия реализовывались на основании вхождения пользователя в группы Active Directory. &lt;/p&gt;

&lt;h3&gt;Архивирование и восстановление объектов&lt;/h3&gt;

&lt;p&gt;У меня ряд проектов были связаны с построением систем по электронному документообороту. В данных системах за несколько лет, а в больших организациях — и за год, накапливалось большое количество документов. С целью уменьшения нагрузки на систему и оптимизации аппаратных ресурсов объекты, которые проходили полный жизненный цикл, через определенный период переносились в отдельную базу данных для хранения. Для некоторых клиентов мы строили отдельный электронный архив с организацией бизнес-процесса для архивариусов, но это уже другая история... &lt;/p&gt;

&lt;p&gt;При проработке требований к архивированию объектов или данных системы необходимо описать, при каких условиях объект можно переносить в архив и как это будет выполняться. Какие операции с заархивированным объектом можно выполнять, есть ли необходимость возвращать объекты из архива и каким образом будет выполняться поиск заархивированных объектов? При проработке требований к архивированию не забывайте о пользователях и их комфорте. &lt;/p&gt;

&lt;p&gt;Я уверен, что многие из вас пользовались таким функционалом, как восстановление данных из корзины. Я считаю, что для любой бизнес-системы функционал по восстановлению данных просто жизненно необходим. Часто возникают ситуации, когда пользователи случайно удаляют объекты в системе и слезно просят их вернуть. Да и со мной такое случалось. &lt;/p&gt;

&lt;p&gt;При проработке требований к хранению удаленных объектов следует учитывать:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Как и кто может восстанавливать данные?&lt;/li&gt;&lt;li&gt;Какой срок хранения удаленных документов?&lt;/li&gt;&lt;li&gt;Есть ли ограничения по объему удаляемого документа?&lt;/li&gt;&lt;/ul&gt;

&lt;h3&gt;Журналирование действий пользователей&lt;/h3&gt;

&lt;p&gt;При проработке требований к журналированию необходимо понимать, зачем это нужно заказчику и как он будет это использовать. От этого будет зависеть, какая информация должна записываться в журналы, в каком виде будет отображаться и какие дополнительные функциональные возможности нужны (группировка, фильтрация, выгрузка в Excel и т. д.). &lt;/p&gt;

&lt;p&gt;Следует учитывать, что в зависимости от функциональных обязанностей пользователям необходима разная информация для анализа. &lt;/p&gt;

&lt;p&gt;Рассмотрим пример. Для сотрудников с функциональной ролью «Аудитор» необходимо понимать, что выполнялось с объектом. Для этого часто реализовывают отдельный интерфейс или вкладку — «История», где отображается информация о том, кто, когда и какое действие выполнял с объектом.&lt;/p&gt;

&lt;p&gt;Сотрудникам с функциональной ролью «Информационная безопасность» необходима более детальная информация, и анализируют они информацию несколько в ином разрезе: что именно пользователь выполнял в системе.&lt;/p&gt;

&lt;p&gt;А для пользователей с функциональной ролью «Сопровождение» необходима информация об ошибках, которые возникают в системе.&lt;/p&gt;

&lt;h2&gt;Отчетность&lt;/h2&gt;

&lt;p&gt;На одной из встреч с заказчиком я задал вопрос: «Какая отчетность должна быть реализована?» Заказчик ответил, что отчетность не нужна. Я переспросил несколько раз, обратив его внимание на разные аспекты, заказчик стоял на своем. Требования к отчетности не были зафиксированы и не вошли в скоуп работ по проекту.&lt;/p&gt;

&lt;p&gt;Через два месяца после выхода в промышленную среду заказчик захотел пул отчетов. Что в этом плохого, спросите вы? Изменение в проектах и тем более после закрытия — это даже хорошо. Отвечу: чтобы удовлетворить требования заказчика, нам пришлось изменять структуру базы данных, а это, в свою очередь, существенно увеличило трудозатраты и бюджет на доработку. Для реализации отдельных требований были необходимы существенные доработки, и заказчик был вынужден отказываться от них. Если бы на старте проекта требования к отчетности были проработаны, можно было бы сэкономить бюджет на другие доработки. &lt;/p&gt;

&lt;p&gt;Исходя из своего опыта я могу сделать вывод: отчетность есть всегда, вне зависимости от системы. Все руководители, которые принимают решение о необходимости покупки или разработки системы, хотят получать количественные показатели системы. Если у вас другое мнение — пишите в комментариях.&lt;/p&gt;

&lt;p&gt;Итак, что я рекомендую учитывать при проработке требований к отчетности:&lt;/p&gt;

&lt;h4&gt;Варианты использования — или, другими словами, как отчетом будут пользоваться&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;Отчет будут печатать — необходимо учитывать, что после печати отчет должен быть читабельный. &lt;/li&gt;&lt;li&gt;Для дальнейшего анализа — необходимо описать требования к визуализации (о визуализации — немного ниже), агрегации, фильтрации, сортировке, группировке. Действия по перечисленным операциям должны быть изначально реализованы — или пользователь должен иметь возможность выполнять эти операции самостоятельно после получения данных?&lt;/li&gt;&lt;li&gt;Гибридный — проводится первоначальная обработка полученных результатов и выводится на печать.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image1_X82b9fM.png"&gt;&lt;/p&gt;

&lt;p&gt;При проработке требований рекомендую искать ответы на следующие вопросы:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Необходимо ли обрабатывать данные после отображения результата запроса?&lt;/li&gt;&lt;li&gt;Есть ли необходимость хранить данные после получения (архив отчетов за период)? Если да, ВНИМАНИЕ: нужно более детально проработать требования к отчетности. Возможно, понадобится организовывать хранилище данных, а это совсем нетривиальная задача.&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Источники данных&lt;/h4&gt;

&lt;p&gt;Для себя я выделяю три источника данных: &lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Внутренняя — база данных системы.&lt;/li&gt;&lt;li&gt;Внешняя — базы данных других систем.&lt;br&gt;&lt;/li&gt; &lt;li&gt;Гибридная — часть данных тянется из внутренней базы данных, а часть — из внешних.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Не раз сталкивался с ситуацией, когда использование данных из внешних систем добавляет ряд проблем: &lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;доступность данных на момент формирования отчета;&lt;/li&gt;&lt;li&gt;производительность построения отчета.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Поэтому тут нужно быть предельно внимательным и сразу предупреждать заказчика о возможных проблемах. &lt;/p&gt;

&lt;h4&gt;Визуализация&lt;/h4&gt;

&lt;p&gt;Если вариант использования — «Для печати», рекомендую проработать так называемый визуальный макет, в котором есть:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;верхний колонтитул;&lt;/li&gt;&lt;li&gt;заголовок (название отчета);&lt;/li&gt;&lt;li&gt;тело отчета — основная часть;&lt;/li&gt;&lt;li&gt;нижний колонтитул.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;В теле отчета следует указывать источники данных. Как правило, я описываю в виде названия таблицы и полей, откуда должно подтягиваться значение. При согласовании требований к отчету следует визуализировать, как отчет будет выглядеть с реальными значениями, подставляемыми из источников данных. &lt;/p&gt;

&lt;p&gt;Если отчет используется «Для дальнейшего анализа», будьте внимательны, так как это может значительно увеличить трудозатраты на разработку визуализации данных. &lt;/p&gt;

&lt;p&gt;Предоставление данных может варьироваться от табличного или матричного представления до отображения данных в виде диаграмм, индикаторов, карт и т. д.&lt;/p&gt;

&lt;p&gt;Самостоятельно реализовать сервис для визуализации данных будет трудозатратно. Уточните, какой ориентировочный срок и бюджет для реализации визуализации данных. Помните, что на рынке есть много хороших решений: PowerBI, Google Data Studio, Tableau и другие. Проанализируйте их.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image3_QNVPQGu.png"&gt;&lt;/p&gt;

&lt;p&gt;Также стоит обратить внимание на то, какие аналитические визуальные компоненты необходимо будет использовать.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Диаграмма&lt;/strong&gt; — представление данных при помощи графических компонентов (линии, точки), связанных со справочниками, имеет одну или несколько числовых шкал.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Индикатор&lt;/strong&gt; — представление показателя для оценки текущего состояния относительно планового значения, с возможностью отобразить шкалу с минимумом и максимумом.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Карта&lt;/strong&gt; — представление показателей, связанных с географическими данными (страна, регион, город и т.д.)&lt;/p&gt;

&lt;p&gt;А возможно, будет достаточно реализовать отображение графиков в Excel.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://s.dou.ua/storage-files/image2_OMWZSFf.jpg" width="600"&gt; &lt;small&gt;&lt;em&gt;&lt;a href="https://mir-olymp.ru/publication/prakticheskaia-rabota-postroenie-grafikov-v-ms-excel.html" target="_blank"&gt;Источник&lt;/a&gt;&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;При проработке требований к отчету не следует забывать, что заказчик может ожидать навигацию:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;возможность настраивать представление данных;&lt;/li&gt;&lt;li&gt;навигацию между разделами отчета.&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Дополнительные возможности&lt;/h4&gt;

&lt;p&gt;Отчеты могут иметь ряд дополнительных возможностей:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Публикация отчетов:&lt;/strong&gt; для некоторых отчетов необходимо иметь возможность публиковать результаты на веб-ресурсах в виде тех же диаграмм, карт и т.д. В данном случае следует учитывать периодичность обновления данных. На практике бывали случаи, когда требования к публикации на веб-ресурсах не прорабатывались, и на первых этапах развития системы просто публиковали изображение, которое предварительно подготавливалось сотрудником, поэтому не забудьте проработать требования не только к публикации, но и к визуализации данных. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Формирование и отправка отчетов по расписанию:&lt;/strong&gt; при проработке требований к формированию и отправке отчетов по расписанию следует учитывать время формирования (как правило, отчеты формируются в нерабочее время, но и в правилах бывают исключения) и способ отправки (электронная почта или сохранение на сетевой ресурс). Следует продумать, с какого электронного адреса будет отправляться отчет, и список получателей. При проработке получателей рекомендую отправлять на группу контактов, группами легче в будущем управлять и сопровождать. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Экспорт данных:&lt;/strong&gt; требования к возможностям экспортировать данные в Excel, Word, PDF или другие форматы. &lt;/li&gt;&lt;/ul&gt;

&lt;h2&gt;Нефункциональные требования&lt;/h2&gt;

&lt;p&gt;На просторах интернета можно найти много информации о том, что такое нефункциональные требования. В данной статье я кратко пробегусь по теории и приведу примеры из практики. Основной мой посыл: что нужно учесть, чтобы требования можно было считать полными. &lt;/p&gt;

&lt;p&gt;Нефункциональные требования — это требования, которые описывают свойства и характеристики системы. Нефункциональные требования делятся на две группы:&lt;br&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Runtime — это требования, которые описывают время работы системы.&lt;/li&gt;&lt;li&gt;Design time — это требования, определяющие аспекты проектирования системы.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;К группе Runtime относят:&lt;br&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Доступность.&lt;/li&gt;&lt;li&gt;Надежность.&lt;/li&gt;&lt;li&gt;Время хранения данных.&lt;/li&gt;&lt;li&gt;Масштабируемость.&lt;/li&gt;&lt;li&gt;Удобство использования.&lt;/li&gt;&lt;li&gt;Безопасность.&lt;/li&gt;&lt;li&gt;Производительность.&lt;/li&gt;&lt;li&gt;Ограничения.&lt;/li&gt;&lt;/ol&gt;

&lt;h3&gt;1. Доступность — требования ко времени непрерывной работы системы&lt;/h3&gt;

&lt;p&gt;Пример требований к доступности: система должна поддерживать режим 24*7 — круглосуточный режим работы. &lt;/p&gt;

&lt;p&gt;При проработке требований к доступности следует учитывать время на так называемые технологические окна, т.е. на обслуживания системы, установку новых релизов. &lt;/p&gt;

&lt;p&gt;Мне больше нравится, как это изложено в требованиях по доступности, ранжированных по девяткам:&lt;/p&gt;

&lt;div&gt;&lt;table class="bordered" style="max-width: 800px;" width="800"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="background: #EFF5FB;" width="200"&gt;&lt;strong&gt;Доступность, %&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="200"&gt;&lt;strong&gt;Время простоя в год&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="200"&gt;&lt;strong&gt;Время простоя в месяц&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="200"&gt;&lt;strong&gt;Время простоя в неделю&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;90 (одна девятка)&lt;/td&gt;&lt;td width="100"&gt;36,5 дней&lt;/td&gt;&lt;td width="100"&gt;72 часа&lt;/td&gt;&lt;td width="100"&gt;16,8 часов&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;95&lt;/td&gt;&lt;td width="100"&gt;18,25 дней&lt;/td&gt;&lt;td width="100"&gt;36 часов&lt;/td&gt;&lt;td width="100"&gt;8,4 часов&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;98&lt;/td&gt;&lt;td width="100"&gt;7,30 дней&lt;/td&gt;&lt;td width="100"&gt;14,4 часов&lt;/td&gt;&lt;td width="100"&gt;3,36 часов&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;99 (две девятки)&lt;/td&gt;&lt;td width="100"&gt;3,65 дней&lt;/td&gt;&lt;td width="100"&gt;7,20 часов&lt;/td&gt;&lt;td width="100"&gt;1,68 часов&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;99,5&lt;/td&gt;&lt;td width="100"&gt;1,83 дней&lt;/td&gt;&lt;td width="100"&gt;3,60 часов&lt;/td&gt;&lt;td width="100"&gt;50,4 минут&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;99,8&lt;/td&gt;&lt;td width="100"&gt;17,52 часов&lt;/td&gt;&lt;td width="100"&gt;86,23 минут&lt;/td&gt;&lt;td width="100"&gt;20,16 минут&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;99,9 (три девятки)&lt;/td&gt;&lt;td width="100"&gt;8,76 часов&lt;/td&gt;&lt;td width="100"&gt;43,2 минут&lt;/td&gt;&lt;td width="100"&gt;10,1 минут&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;99,95&lt;/td&gt;&lt;td width="100"&gt;4,38 часов&lt;/td&gt;&lt;td width="100"&gt;21,56 минут&lt;/td&gt;&lt;td width="100"&gt;5,04 минут&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;99,99 (четыре девятки)&lt;/td&gt;&lt;td width="100"&gt;52,56 минут&lt;/td&gt;&lt;td width="100"&gt;4,32 минут&lt;/td&gt;&lt;td width="100"&gt;1,01 минут&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;99,999 (пять девяток)&lt;/td&gt;&lt;td width="100"&gt;5,26 минут&lt;/td&gt;&lt;td width="100"&gt;25,9 секунд&lt;/td&gt;&lt;td width="100"&gt;6,05 секунд&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;99,9999 (шесть девяток)&lt;/td&gt;&lt;td width="100"&gt;31,5 секунд&lt;/td&gt;&lt;td width="100"&gt;2,59 секунд&lt;/td&gt;&lt;td width="100"&gt;0,605 секунд&lt;/td&gt;&lt;/tr&gt;

&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;Сразу скажу, все заказчики хотят доступность в шесть девяток, но когда начинаем прорабатывать аппаратную архитектуру, соглашаются на &lt;nobr&gt;95-99&lt;/nobr&gt; :-D &lt;/p&gt;

&lt;h3&gt;2. Надежность &lt;/h3&gt;

&lt;p&gt;Требования к надежности описывают поведение системы в нештатных ситуациях. Требования к надежности должны предусматривать:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Резервирование критически важных компонентов и данных системы и отсутствие единой точки отказа.&lt;/li&gt;&lt;li&gt;Использование технических средств с избыточными компонентами и возможностью их горячей замены.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Ниже приведу несколько примеров:&lt;br&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Отказ аппаратной составляющей архитектуры &lt;br&gt;&lt;ul&gt;&lt;li&gt;Система должна сохранять работоспособность при отказе или выходе из строя веб-серверов.&lt;/li&gt;&lt;li&gt;Необходимо обеспечить сохранение всей накопленной информации на момент отказа или выхода из строя одного из дисковых накопителей.&lt;/li&gt;&lt;li&gt;В случае полного отключения электроэнергии система должна обработать и после возобновления электроэнергии запустить повторно на выполнение все незавершенные операции.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Сбои в программной логике&lt;br&gt;&lt;ul&gt;&lt;li&gt;Система должна обеспечивать работоспособность в случае сбоя одного из своих модулей.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Перебои работы каналов связи или локальной сети:&lt;br&gt;&lt;ul&gt;&lt;li&gt;Система должна обеспечивать гарантированную доставку информации при обмене данными между предприятиями холдинга. &lt;/li&gt;&lt;li&gt;Необходимо реализовать квитанцию о доставке информационного пакета. В случае если квитанция не получена в течение 5 минут, необходимо повторно отправить информационный пакет.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;При проработке требований к надежности следует изначально проанализировать, каким образом это требование может быть достигнуто. В данном вопросе не стесняйтесь обращаться за помощью к архитекторам, администраторам баз данных или другим техническим специалистам. Некоторые требования могут существенно увеличить стоимость как реализации системы, так и стоимость аппаратных средств. &lt;/p&gt;

&lt;h3&gt;3. Требования к времени хранения данных&lt;/h3&gt;

&lt;p&gt;За время использования системы в базе данных может накапливаться множество информации, из-за чего производительность системы или отдельных ее компонентов начинает существенно снижаться. При этом пользователям все сложнее и сложнее находить необходимую информацию. &lt;/p&gt;

&lt;p&gt;Чтобы избежать подобных трудностей, следует уточнить у заказчика возможность удаления документов после истечения сроков. Сроки хранения многих видов документов регламентируются законодательством. Также следует предложить варианты организации архивов. &lt;/p&gt;

&lt;p&gt;При проработке архивирования данных не забывайте о возможных связях объектов вашей системы.&lt;/p&gt;

&lt;h3&gt;4. Масштабируемость&lt;/h3&gt;

&lt;p&gt;Требования к масштабируемости описывают, как система должна сохранять свою работоспособность при возрастании нагрузки. К примеру, при увеличении количества пользователей, которые работают с системой, или увеличении хранимого контента и так далее.&lt;/p&gt;

&lt;p&gt;Как правило, выделяют два направления масштабирования:&lt;br&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Вертикальное масштабирование — это увеличение производительности компонентов системы с целью повышения общей производительности. К примеру, увеличение дискового пространства или CPU. &lt;/li&gt;&lt;li&gt;Горизонтальное масштабирование — разбиение системы на более мелкие структурные компоненты и разнесение их по отдельным физическим машинам (или их группам) и (или) увеличение количества серверов, параллельно выполняющих одну и ту же функцию.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;Следует заметить, что вертикальное масштабирование, как правило, направлено на повышение производительности системы, а горизонтальное, помимо повышения производительности, на отказоустойчивость.&lt;/p&gt;

&lt;p&gt;Примеры: при разработке архива документов следует предусмотреть возможность масштабирования системы за счет добавления дискового пространства. При увеличении количества работающих пользователей с системой следует обеспечить быстродействие отклика страниц системы в 5 секунд за счет горизонтального масштабирования — увеличения аппаратных мощностей. &lt;/p&gt;

&lt;h3&gt;5. Требования к удобству использования&lt;/h3&gt;

&lt;p&gt;Пример из реального документа с требованиями:&lt;/p&gt;

&lt;p&gt;Система должна иметь удобный, интуитивно понятный и дружественный интерфейс. &lt;/p&gt;

&lt;p&gt;Когда я вижу подобное в требованиях, сразу задаю вопрос: какие критерии проверки удобства и дружественности интерфейса?&lt;/p&gt;

&lt;p&gt;Недостаточно написать — удобный, интуитивно понятный и дружественный. Следует раскрыть эти сущности. &lt;/p&gt;

&lt;p&gt;Для себя выделяю семь пунктов юзабилити для проверки требований на полноту:&lt;br&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Шрифты:&lt;/strong&gt; осмысленные размеры шрифтов и их поведение при адаптивном дизайне.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Адаптивность:&lt;/strong&gt; проработайте размещение и поведение элементов системы при адаптивности. Максимальное и минимальное разрешение. Разрешение, при котором изменяется размещение элементов. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Ошибки:&lt;/strong&gt; информативная обработка сообщений об ошибках. Недостаточно показать код ошибки — следует сообщить, что пользователю делать с этой ошибкой. А также потрудитесь отдельно проработать требования к страницам с информацией об ошибке. &lt;/li&gt;

&lt;img src="https://s.dou.ua/storage-files/image4_FM20qtD.jpg" width="600"&gt;

&lt;li&gt;&lt;strong&gt;Навигация:&lt;/strong&gt; отдельно раскрывал эту тему во &lt;a href="https://dou.ua/lenta/articles/techniques-for-developing-requirements-2/" target="_blank"&gt;второй&lt;/a&gt; части статьи.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Поиск:&lt;/strong&gt; для удобства пользователя поиск размещают практически на всех интерфейсах пользователя (я не говорю сейчас о диалоговых или информационных интерфейсах). Поиск информации может быть глобальным — в рамках всей системы, или локальным — в рамках определенного модуля, а также контекстным. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Кроссбраузерность:&lt;/strong&gt; если у вас система работает через браузеры, опишите браузеры и их версии, на которых должна функционировать система. Тут важный аспект: чем больше браузеров, тем больше работы у разработчиков и верстальщиков, а также увеличивается время на тестирование. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Обработка отдельных элементов:&lt;/strong&gt; к примеру, ссылки, которые посещал пользователь, должны отображаться не синим, а фиолетовым. Также необходимо указать коды цветовой гаммы: цвет активной ссылки — #0000FF, цвет посещенной ссылки — #800080&lt;/li&gt;&lt;/ol&gt;

&lt;h3&gt;6. Требования к безопасности &lt;/h3&gt;

&lt;p&gt;Требования к безопасности бывают трех категорий:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;связанные с разграничением доступа;&lt;/li&gt;&lt;li&gt;связанные с работой с приватными данными;&lt;/li&gt;&lt;li&gt;направленные на снижение рисков от внешних атак.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Для понимания ниже приведу несколько примеров каждой категории.&lt;/p&gt;

&lt;p&gt;Примеры требований с разграничением доступа:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Необходимо обеспечить возможность создавать как групповые, так и индивидуальные роли.&lt;/li&gt;&lt;li&gt;В системе должна быть реализована сквозная аутентификация active directory. &lt;/li&gt;&lt;li&gt;Ролевая модель должна управляться на уровне active directory путем добавления пользователей в группы active directory.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Примеры требований, связанных с работой с приватными данными:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Действия: создание, просмотр, редактирование, удаление документов с параметром «Коммерческая тайна» необходимо фиксировать в отдельном электронном журнале «Документы — коммерческая тайна».&lt;/li&gt;&lt;li&gt;Документы с параметром «Коммерческая тайна» должны храниться в зашифрованном виде.&lt;/li&gt;&lt;li&gt;Все документы с параметром «Коммерческая тайна» должны отдельно согласовываться с руководителем департамента информационной безопасности. &lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Примеры требований, направленных на снижение рисков от внешних атак:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Обмен документами между компаниями холдинга должен выполняться только через сервисную шину предприятия.&lt;/li&gt;&lt;li&gt;Веб-приложение должно использовать протокол https.&lt;/li&gt;&lt;/ul&gt;

&lt;h3&gt;7. Требования к производительности&lt;/h3&gt;

&lt;p&gt;Требования к производительности описывают количество пользователей, которые будут работать с системой, количество транзакций, время реакции или загрузки страниц, скорость и пропускную способность каналов связи.&lt;/p&gt;

&lt;p&gt;При проработке требований к количеству работающих пользователей с системой следует учитывать общее количество пользователей, одновременно работающих, а также прогнозируемый прирост пользователей. В большинстве источников, которые трактуют требования к производительности, упускают прогноз по приросту пользователей. На одном из проектов заказчик сообщил, что с системой будет работать не более 2 000 пользователей, соответственно, все расчеты, оптимизации и нагрузочные тесты были рассчитаны на 2 000 пользователей. При этом заказчик упустил одну деталь: в конце года планируется их слияние с группой компаний, и количество пользователей возрастет до 80 000, и система должна обеспечить одновременную работу более 2 000 пользователей. Думаю, дальнейшие комментарии излишни. &lt;/p&gt;

&lt;p&gt;Одним из важных факторов может оказаться количество выполняемых транзакций. Также этот фактор может повлиять аппаратную архитектуру. На одном из проектов не учли, что система должна была выполнять более 40 000 транзакций в минуту, и система просто не выдерживала. Нам пришлось остановить работу пользователей в системе более чем на два месяца и проводить изменения ядра и оптимизацию пользовательских функций. Благо, что на время остановки клиент мог работать в старой системе, и нам, помимо разработки, пришлось еще выполнять работы по повторному экспорту данных. &lt;/p&gt;

&lt;p&gt;В документах часто можно встретить требования в стиле: «Страница должна загружаться не более чем за 5 секунд». При этом аналитики не задумываются о таких моментах, как быстродействие пользовательских ПК или других девайсов, потерь в сети и других проблем, не связанных с быстродействием самой системы. Что делать, если заказчик таки требует указать требования к быстродействию? Варианта два: или указывайте параметры, при каких вы обеспечите быстродействие в 5 секунд, или проводите тестирование с серверов, где развернута система — это значительно уменьшит риски, что на быстродействие повлияют внешние факторы. &lt;/p&gt;

&lt;p&gt;Одним из интереснейших проектов из моей практики был проект по внедрению CRM-системы на 150 000 пользователей. Не учли такой момент, как слишком большой трек отдаленных рабочих мест с реально древним оборудованием и быстродействием каналов связи. В некоторых клиентских точках из-за быстродействия каналов связи система просто падала по таймауту.&lt;/p&gt;

&lt;h3&gt;8. Ограничения&lt;/h3&gt;

&lt;p&gt;При описании ограничений следует указывать, при каких условиях система должна выполнять возложенные на нее задачи. К примеру, объем доступной памяти, дискового пространства, пропускная способность сети, версионность браузеров. В седьмом пункте «Требований к производительности» я указывал примеры проблемных ситуаций, с которыми сталкивался в своей практике. &lt;/p&gt;

&lt;p&gt;На одном из проектов мы с удивлением узнали, что у клиента есть ПК, на которых установлена ОС Windows XP c браузером IE 8, и это очень ограничивало нас в разработке, а именно — в выборе технологии реализации.&lt;/p&gt;

&lt;p&gt;К группе Design time относят:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Требования к расширяемости.&lt;/li&gt;&lt;li&gt;Требования к переносимости.&lt;/li&gt;&lt;li&gt;Требования к взаимодействию.&lt;/li&gt;&lt;li&gt;Требования к поддержке.&lt;/li&gt;&lt;li&gt;Требования к возможности тестирования.&lt;/li&gt;&lt;li&gt;Требования к локализации.&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Требования к расширяемости&lt;/h4&gt;

&lt;p&gt;Во многих источниках при описании требований к расширяемости можно встретить определение: требование к расширяемости приложения или системы в связи с появлением новых функциональных требований тесно связано с таким архитектурным атрибутом качества, как переносимость кода.&lt;/p&gt;

&lt;p&gt;На самом деле я очень редко в документах встречал требования к расширяемости. Однако не стоит забывать, что такие требования могут быть. К требованиям к расширяемости можно отнести идеологию OpenSource или предоставление API. Вот несколько примеров: &lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Необходимо, чтобы в будущем была возможность интеграции со справочниками валют Национального банка Украины.&lt;/li&gt;&lt;li&gt;Необходимо, чтобы в будущем система могла интегрироваться со страницей компании на фейсбуке.&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Требования к переносимости&lt;/h4&gt;

&lt;p&gt;В требованиях к переносимости описывают требования работы системы на разных платформах.&lt;/p&gt;

&lt;p&gt;Переносимость системы включает:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Перенос системы на другую среду (компьютер, ферму серверов) аналогичной архитектуры.&lt;/li&gt;&lt;li&gt;Установка или переустановка из дистрибутивных файлов на другую среду (компьютер, ферму серверов) аналогичной архитектуры.&lt;/li&gt;&lt;li&gt;Сборка исполняемых программ для разных платформ из исходного кода.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Также встречаются системы, которые запускаются с USB-накопителей. Для запуска подобных систем нужен ПК с операционной системой, а все конфигурационные и исполнительные компоненты находятся на съемном устройстве. &lt;/p&gt;

&lt;h4&gt;Требования к взаимодействию&lt;/h4&gt;

&lt;p&gt;Требования к взаимодействию описывают требования к системной интеграции систем с целью, чтобы интегрируемые системы могли функционировать вместе как единая система. &lt;/p&gt;

&lt;p&gt;На моей практике для построения организационной структуры предприятий мы использовали разнообразные HR-системы или данные из Active Directory, а иногда и данные из нескольких систем. Для этого должен быть некий уникальный идентификатор, который используется с целью построения интеграционных связей между системами. &lt;/p&gt;

&lt;p&gt;Не следует забывать, что ваша система также может являться мастер-системой для других систем, и необходимо проработать механизмы передачи данных в другие системы. На некоторых проектах при прохождении пользователями по бизнес-процессу наша система вызывала сервисы и процедуры других систем и передавала им данные. &lt;/p&gt;

&lt;p&gt;Для более сложных интеграций используют протоколы обмена данными между системами или, как пример, реализовывают API (application programming interface). &lt;/p&gt;

&lt;p&gt;Зачастую для разработки API разработчикам достаточно описания данных в следующем виде:&lt;/p&gt;

&lt;div&gt;&lt;table class="bordered" style="max-width: 600px;" width="600"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="background: #EFF5FB;" width="100"&gt;&lt;strong&gt;№&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="100"&gt;&lt;strong&gt;Название поля&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="100"&gt;&lt;strong&gt;Описание поля&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="100"&gt;&lt;strong&gt;Тип данных&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="100"&gt;&lt;strong&gt;Обязательность дополнения&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="100"&gt;&lt;strong&gt;Комментарий&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;1&lt;/td&gt;&lt;td width="100"&gt;UserId&lt;/td&gt;&lt;td width="100"&gt;Уникальный идентификатор&lt;/td&gt;&lt;td width="100"&gt;Integer&lt;/td&gt;&lt;td width="100"&gt;Да&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;2&lt;/td&gt;&lt;td width="100"&gt;Surname&lt;/td&gt;&lt;td width="100"&gt;Фамилия&lt;/td&gt;&lt;td width="100"&gt;String&lt;/td&gt;&lt;td width="100"&gt;Да&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;3&lt;/td&gt;&lt;td width="100"&gt;Name&lt;/td&gt;&lt;td width="100"&gt;Имя&lt;/td&gt;&lt;td width="100"&gt;String&lt;/td&gt;&lt;td width="100"&gt;Да&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;4&lt;/td&gt;&lt;td width="100"&gt;Patronymic&lt;/td&gt;&lt;td width="100"&gt;Отчество&lt;/td&gt;&lt;td width="100"&gt;String&lt;/td&gt;&lt;td width="100"&gt;Да&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;5&lt;/td&gt;&lt;td width="100"&gt;Phone&lt;/td&gt;&lt;td width="100"&gt;Телефон&lt;/td&gt;&lt;td width="100"&gt;String&lt;/td&gt;&lt;td width="100"&gt;Нет&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;Для интеграции систем аналитики описывают мапинг полей:&lt;/p&gt;

&lt;div&gt;&lt;table class="bordered" style="max-width: 1200px;" width="1200"&gt;&lt;tbody&gt;

&lt;tr&gt;&lt;td style="background: #EFF5FB;" width="100"&gt;&lt;strong&gt;№&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="200"&gt;&lt;strong&gt;Описание поля&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="200"&gt;&lt;strong&gt;Название поля&lt;br&gt;Система 1&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="200"&gt;&lt;strong&gt;Тип данных&lt;br&gt;Система 1&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="200"&gt;&lt;strong&gt;Название поля&lt;br&gt;Система 2&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="200"&gt;&lt;strong&gt;Тип данных&lt;br&gt;Система 2&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="100"&gt;&lt;strong&gt;Комментарий&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;1&lt;/td&gt;&lt;td width="100"&gt;Уникальный идентификатор&lt;/td&gt;&lt;td width="100"&gt;UserId&lt;/td&gt;&lt;td width="100"&gt;Integer (12)&lt;/td&gt;&lt;td width="100"&gt;TabId&lt;/td&gt;&lt;td width="100"&gt;Integer (12)&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;2&lt;/td&gt;&lt;td width="100"&gt;Фамилия&lt;/td&gt;&lt;td width="100"&gt;Surname&lt;/td&gt;&lt;td width="100"&gt;String (256)&lt;/td&gt;&lt;td width="100"&gt;Sname&lt;/td&gt;&lt;td width="100"&gt;String (256)&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;3&lt;/td&gt;&lt;td width="100"&gt;Имя&lt;/td&gt;&lt;td width="100"&gt;Name&lt;/td&gt;&lt;td width="100"&gt;String (256)&lt;/td&gt;&lt;td width="100"&gt;Name&lt;/td&gt;&lt;td width="100"&gt;String (256)&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;4&lt;/td&gt;&lt;td width="100"&gt;Отчество&lt;/td&gt;&lt;td width="100"&gt;Patronymic&lt;/td&gt;&lt;td width="100"&gt;String (256)&lt;/td&gt;&lt;td width="100"&gt;MName&lt;/td&gt;&lt;td width="100"&gt;String (256)&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;5&lt;/td&gt;&lt;td width="100"&gt;Телефон&lt;/td&gt;&lt;td width="100"&gt;Phone&lt;/td&gt;&lt;td width="100"&gt;String (256)&lt;/td&gt;&lt;td width="100"&gt;MobPhone&lt;/td&gt;&lt;td width="100"&gt;String (256)&lt;/td&gt;&lt;td width="100"&gt; — &lt;/td&gt;&lt;/tr&gt;

&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;При мапинге полей следует обращать внимание на совпадение типа полей и их длину (в таблице указал в скобках максимальное количество символов). &lt;/p&gt;

&lt;h4&gt;Требования к поддержке&lt;/h4&gt;

&lt;p&gt;Требования к поддержке описывают, насколько легко должно быть поддерживать систему. Это относится к возможности сотрудников поддержки отслеживать, выявлять, анализировать причины или изолировать сбои и ошибки в работе системы. Включение функций, которые облегчают обслуживание, обеспечивает более эффективное сопровождение продукта, сокращение эксплуатационных расходов и обеспечение непрерывности бизнеса.&lt;/p&gt;

&lt;p&gt;Примеры функций:&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Уведомление в службу поддержки об ошибках или сбоях в работе серверов через электронную почту или SMS-сообщения.&lt;/li&gt;&lt;li&gt;Мониторинговые модули работоспособности системы, фермы серверов или сети.&lt;/li&gt;&lt;li&gt;Регистрация событий в системе и логирование сбоев и ошибок.&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Требования к возможности тестирования&lt;/h4&gt;

&lt;p&gt;Требования к возможности тестирования включают в себя требования к автоматическому, нагрузочному и ручному (дымовое, регрессионное, функциональное и т.д.) тестированию, использование определенного инструментария, описание требуемых артефактов (чек-листы или тест-кейсы). &lt;/p&gt;

&lt;p&gt;Пример шаблона тест-кейсов:&lt;/p&gt;

&lt;div&gt;&lt;table class="bordered" style="max-width: 700px;" width="700"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="background: #EFF5FB;" width="100"&gt;&lt;strong&gt;№&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="300"&gt;&lt;strong&gt;Действие&lt;/strong&gt;&lt;/td&gt;&lt;td style="background: #EFF5FB;" width="300"&gt;&lt;strong&gt;Результат&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;1&lt;/td&gt;&lt;td width="100"&gt;Зарегистрироваться в администраторской части&lt;/td&gt;&lt;td width="100"&gt;На экране отобразится иерархический список разделов и действий&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;2&lt;/td&gt;&lt;td width="100"&gt;Перейти в раздел управления пользователями&lt;/td&gt;&lt;td width="100"&gt;В правой верхней части экрана появится список действий, в правой нижней части — список пользователей&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td width="100"&gt;3&lt;/td&gt;&lt;td width="100"&gt;Выбрать функцию «Добавить пользователя»&lt;/td&gt;&lt;td width="100"&gt;На экране появится форма для добавления нового пользователя:&lt;br&gt;&lt;ul&gt;&lt;li&gt;имя пользователя;&lt;/li&gt;&lt;li&gt;личная информация;&lt;/li&gt;&lt;li&gt;роль (выбор из списка);&lt;/li&gt;&lt;li&gt;кнопка «Добавить пользователя»&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;

&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;Также иногда прописывают требования к самому процессу тестирования, к примеру: «Тестирование на тестовой среде заказчика должен выполнить только заказчик». Описывают статусы и инструменты, где будут заводиться дефекты, и порядок их обработки. &lt;/p&gt;

&lt;h4&gt;Требования к локализации&lt;/h4&gt;

&lt;p&gt;Требования к локализации содержат перечень языков, на которых должна функционировать система. А также возможность добавления самостоятельно новой локализации в систему. Данные требования также могут существенно увеличивать трудозатраты по проекту. &lt;/p&gt;

&lt;p&gt;На одном из проектов не были описаны требования к локализации. Заказчик у нас был из чудесного города Тбилиси. К моему большому удивлению, мы обнаружили, что аналитики недостаточно внимания уделили требованиям к локализации, и когда разработчики реализовали модуль локализации, они попросили все термины, которые необходимо перевести на грузинский язык... И вот тут началась паника: что делать, как переводить и как тестировать... После переговоров с заказчиком удалось его уговорить, что перевод он предоставит и тестирование на грузинской локализации он также проведет. И вопрос, что нам пришлось бы делать, если бы не удалось уговорить заказчика, к счастью, остался только в моих мыслях...&lt;/p&gt;

&lt;p&gt;Вместо заключения хотел бы заметить, что техники не такие уж и секретные, и известные многим. Вот только почему не все они прорабатываются или им уделяется недостаточно внимания в рамках проработки и формализации требований? &lt;/p&gt;

&lt;p&gt;Уверен, что моя статья, как минимум, натолкнет вас на размышления. &lt;/p&gt;

&lt;p&gt;Буду благодарен за комментарии и дополнения к техникам, которые я не раскрыл в своей статье. По этой теме готовлю тренинг, кому интересно, отслеживайте в социальных сетях и в нашем &lt;a href="https://www.facebook.com/groups/ITNetworkBAandPM/" target="_blank"&gt;коммьюнити&lt;/a&gt;. Подискутировать на данную тему готов на клубных встречах IT Network и конференциях. &lt;/p&gt;

&lt;p&gt;Гармонии вам и процветания! До новых встреч на страницах DOU!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Артур Селецкий</dc:creator><pubDate>Mon, 13 Jan 2020 13:00:03 +0200</pubDate><guid>https://dou.ua/lenta/articles/techniques-for-developing-requirements-3/</guid></item><item><title>Зарплати українських розробників — грудень 2019</title><link>https://dou.ua/lenta/articles/salary-report-devs-dec-2019/</link><description>&lt;p&gt;З 2 грудня до 5 січня ми проводили чергове анонімне зарплатне опитування, в якому взяли участь 10 187 ІТ-спеціалістів. &lt;a href="https://dou.ua/lenta/tags/%D0%B7%D0%B0%D1%80%D0%BF%D0%BB%D0%B0%D1%82%D1%8B/" target="_blank"&gt;Як і влітку&lt;/a&gt;, результати публікуватимемо у трьох частинах: зарплати розробників, зарплати тестувальників та зарплати інших технічних і нетехнічних спеціалістів.&lt;/p&gt;

&lt;p&gt;У цій статті розглядаємо зарплати розробників, їх серед опитаних — 4921 спеціаліст. До розробників відносимо Software Engineer, TechLead і System Architect. Також цього разу ми дещо оновили анкету і для програмістів додали можливість обрати додаткову мову програмування й фреймворк/бібліотеку, що використовуються на поточній посаді. &lt;/p&gt;

&lt;p&gt;Усі зарплати вказані в доларах США (за курсом міжбанку), чистими (після сплати податків). Для оцінки зарплат у вибірках використовується &lt;a href="https://uk.wikipedia.org/wiki/%D0%9C%D0%B5%D0%B4%D1%96%D0%B0%D0%BD%D0%B0_(%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0)" target="_blank"&gt;медіана&lt;/a&gt;. Статті з результатами минулих опитувань &lt;a href="http://dou.ua/lenta/tags/%D0%B7%D0%B0%D1%80%D0%BF%D0%BB%D0%B0%D1%82%D1%8B/" target="_blank"&gt;тут&lt;/a&gt;. Дані на GitHub та у віджет заллємо десь за тиждень. &lt;/p&gt;

&lt;h2 id="portrait" style="font-size: 30px; border-bottom: 1px solid #ccc; margin-bottom: 15px; padding-bottom: 0;"&gt;Портрет учасників опитування &lt;a class="anchor" href="#portrait"&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;object class="dou-charts-desktop" data="https://s.dou.ua/files/lenta/salary-report-devs-dec-2019/svg/01-soc-dem.svg"&gt;&lt;/object&gt;&lt;object class="dou-charts-mobile" data="https://s.dou.ua/files/lenta/salary-report-devs-dec-2019/svg/01-soc-dem-mobile.svg"&gt;&lt;/object&gt;&lt;/p&gt;

&lt;p&gt;&lt;object class="dou-charts-desktop" data="https://s.dou.ua/files/lenta/salary-report-devs-dec-2019/svg/02-tech.svg"&gt;&lt;/object&gt;&lt;object class="dou-charts-mobile" data="https://s.dou.ua/files/lenta/salary-report-devs-dec-2019/svg/02-tech-mobile.svg"&gt;&lt;/object&gt;&lt;/p&gt;

&lt;h2 id="salary" style="font-size: 30px; border-bottom: 1px solid #ccc; margin-bottom: 15px; padding-bottom: 0;"&gt;Середні зарплати &lt;a class="anchor" href="#salary"&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;У всіх категорій, окрім Software Engineer, за останні півроку середня зарплата по Україні зросла: +$200 у Software Architect, +$150 у TechLead, +$100 у Senior Software Engineer і +$50 у Junior SE. У Software Engineer зростання відбулося у Києві, Харкові, Дніпрі й Запоріжжі, в інших містах середня зарплата SE або не змінилася, або навіть зменшилася (в Одесі — -$220, у Вінниці — -$100). &lt;/p&gt;

&lt;h4&gt;Динаміка&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-dynamic"&gt;&lt;/div&gt;

&lt;p&gt;Середні зарплати Senior-ів у Києві досягли позначки $4000, і це на $500 і $250 вище, ніж у Харкові і Львові відповідно. Щодо джуніорів, то найменше (серед топ-5 міст) отримують початківці у Харкові ($600), а найбільше — у Києві ($840). &lt;/p&gt;

&lt;h4&gt;За посадами&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-sal-positions"&gt;&lt;/div&gt;

&lt;p&gt;Доволі висока середня зарплата розробників в Івано-Франківську — $2000. В той час як в Одесі середня зарплата — $1550. &lt;/p&gt;

&lt;p&gt;Цікаво, що середня зарплата Kotlin-розробників у Києві і Львові на $800 вища, ніж у Харкові. Вища за харківську й середня зарплата львівських JavaScript-розробників — на $185. &lt;/p&gt;

&lt;h4&gt;За містами&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-sal-city"&gt;&lt;/div&gt;

&lt;p&gt;Середня зарплата Senior Scala за півроку зменшилася на $200, але все одно залишається найвищою серед інших мов програмування. Серед Software Engineer найнижча середня зарплата у 1C-розробників ($1400), а найвища у Go ($2800).&lt;/p&gt;

&lt;h4&gt;За мовами програмування&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-sal-tech"&gt;&lt;/div&gt;

&lt;p&gt;Середня зарплата Senior-розробників у продуктовій компанії на $400 вища, ніж в аутсорсинговій. Більше у продукті отримують і джуніори — $800 проти $700 в аутсорсі та $600 у стартапі.&lt;/p&gt;

&lt;h4&gt;За типом компаній&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-sal-company-type"&gt;&lt;/div&gt;

&lt;p&gt;Найвищі середні зарплати серед випускників ДонНТУ, КНУ ім. Шевченка та НТУУ «КПІ» — у всіх по $3000. Серед студентів, що вже працюють, найвищі зарплати у тих, хто навчається у ДНУ ім. Гончара, НТУ «ХПІ», Львівській політехніці та КНУ ім. Шевченка — понад $1000. Найнижча середня зарплата у студентів ЛНУ ім. Франка — $600.&lt;/p&gt;

&lt;h4&gt;За вишами&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-sal-universitet"&gt;&lt;/div&gt;

&lt;h2 id="techsalary" style="font-size: 30px; border-bottom: 1px solid #ccc; margin-bottom: 15px; padding-bottom: 0;"&gt;Середні зарплати: динаміка, фреймворки й порівняння&lt;a class="anchor" href="#techsalary"&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Як вже зазначали вище, цього року ми додали декілька уточнювальних запитань: щодо додаткової мови програмування та фреймворків/бібліотек/платформ, що використовуються на поточній посаді. Нижче представляємо перелік основних мов програмування з динамікою за 8 років, а також з розбивкою за додатковою мовою та фреймворками. &lt;/p&gt;

&lt;h3&gt;Java&lt;/h3&gt;

&lt;p&gt;Почнемо з Java, за останні півроку лише позитивна динаміка: середня зарплата Junior SE зросла на $68, SE — на $100, Senior SE — на $130. А за останні п’ять років середні зарплати збільшилися на $68, $325 і $600 відповідно.&lt;/p&gt;

&lt;h4&gt;Динаміка середніх зарплат Java&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-dynamic-java"&gt;&lt;/div&gt;

&lt;p&gt;Щодо фреймворків і бібліотек, то найпопулярнішими серед Java-розробників є Spring і Hibernate (601 і 346 анкет). Всі інші варіанти зібрали суттєво менше відповідей. А ось найвищі середні зарплати у тих, хто використовує в роботі Play, Apache Spark, Node.js. &lt;/p&gt;

&lt;p&gt;Серед додаткових мов програмування найбільш популярними у Java-розробників є JavaScript, SQL і Kotlin. А ось найвищі середні зарплати у тих, хто, окрім Java, ще використовує Go і Python — $3400 і $3100 відповідно. Цікаво, що майже кожен третій Java-розробник не використовує додаткову мову програмування на поточній роботі. &lt;/p&gt;

&lt;h4&gt;Середні зарплати Java-розробників з розбивкою за фреймворками та додатковою мовою програмування&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-add-java"&gt;&lt;/div&gt;

&lt;h3&gt;JavaScript&lt;/h3&gt;

&lt;p&gt;Переходимо до JavaScript, за останні півроку середня зарплата Junior SE зросла на $50, а SE — на $100. Середня зарплата сеньорів з червня не змінилася, але за останні п’ять років вона збільшилася на $775. А от у джуніорів навпаки з 2014 року негативна динаміка — середня зарплата зменшилася з $750 до $650.&lt;/p&gt;

&lt;h4&gt;Динаміка середніх зарплат JavaScript&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-dynamic-js"&gt;&lt;/div&gt;

&lt;p&gt;Серед найбільш популярних фреймворків і бібліотек у JavaScript-розробників: React.js (792 анкети), Node.js (559), Angular/Angular.js (409), Vue.js (212), Express (188), jQuery (168), React Native (158). Найвищі середні зарплати серед цих інструментів у Node.js ($2250), Angular/Angular.js ($2100) і Express ($2000).&lt;/p&gt;

&lt;p&gt;70% JavaScript-розробників використовують на поточній роботі лише одну мову програмування. Серед тих, хто використовує додаткову мову, найбільш популярною є PHP (119 анкет). Але, схоже, що на рівень зарплати це не впливає: середня зарплата JS-розробників, що використовують PHP, на $200 нижча, ніж тих, хто використовує лише JavaScript. &lt;/p&gt;

&lt;h4&gt;Середні зарплати JavaScript-розробників з розбивкою за фреймворками та додатковою мовою програмування&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-add-js"&gt;&lt;/div&gt;

&lt;h3&gt;C#/.NET&lt;/h3&gt;

&lt;p&gt;Серед C#/.NET середня зарплата за півроку зросла лише у джуніорів — на $100. У SE і Senior SE середня зарплата не змінюється вже рік. &lt;/p&gt;

&lt;h4&gt;Динаміка середніх зарплат C#/.NET&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-dynamic-cnet"&gt;&lt;/div&gt;

&lt;p&gt;.NET (544 анкети), .NET Core (472) і ASP.NET (437) — найбільш популярні платформи серед .NET-розробників. Також доволі популярний фреймворк Angular/Angular.js — 195 анкет. Але найвищі середні зарплати у тих, хто, окрім стандартних платформ, використовує у роботи React.js ($3000) і Xamarin ($2700). &lt;/p&gt;

&lt;p&gt;Майже половина .NET-розробників використовує JavaScript як додаткову мову програмування. Але найвищі зарплати серед тих, хто додатково працює з SQL — $2500 проти $2000 серед тих, хто використовує лише C#. &lt;/p&gt;

&lt;h4&gt;Середні зарплати C#/.NET-розробників з розбивкою за фреймворками та додатковою мовою програмування&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-add-cnet"&gt;&lt;/div&gt;

&lt;h3&gt;PHP&lt;/h3&gt;

&lt;p&gt;За останні півроку зарплати PHP розробників практично не змінилися — лише трішки зросла середня зарплата джуніорів (на $50). &lt;/p&gt;

&lt;h4&gt;Динаміка середніх зарплат PHP&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-dynamic-php"&gt;&lt;/div&gt;

&lt;p&gt;Laravel (262 анкети), jQuery (214), Vue.js (122) — найпопулярніші фреймворки і бібліотеки серед PHP-розробників. 70% респондентів використовують JavaScript як додаткову мову програмування.&lt;/p&gt;

&lt;h4&gt;Середні зарплати PHP-розробників з розбивкою за фреймворками та додатковою мовою програмування&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-add-php"&gt;&lt;/div&gt;

&lt;h3&gt;Python&lt;/h3&gt;

&lt;p&gt;Зарплата Senior Python за півроку не змінилася, проте вона суттєво зросла у першому півріччі (на $500). Цікаво, що за останні п’ять років середня зарплата Senior SE виросла на $1100, а ось SE і Junior SE лише на $200 і $100 відповідно.&lt;/p&gt;

&lt;h4&gt;Динаміка середніх зарплат Python&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-dynamic-python"&gt;&lt;/div&gt;

&lt;p&gt;Серед найбільш популярних фреймворків у Python-розробників — це Django (169 анкет) і Flask (127). Щодо додаткових мов програмування, то частіше за інші розробники на Python використовують в роботі JavaScript, але найвища середня зарплата у тих, хто має у своєму арсеналі Go — $2700. &lt;/p&gt;

&lt;h4&gt;Середні зарплати Python-розробників з розбивкою за фреймворками та додатковою мовою програмування&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-add-python"&gt;&lt;/div&gt;

&lt;h3&gt;C++&lt;/h3&gt;

&lt;p&gt;На $250 зросла середня зарплата Senior С++ розробників за останні півроку. Також на $100 збільшилася зарплата Junior C++ і досягла позначки $900. Наразі вона найвища серед зарплат джуніорів за основними мовами програмування. &lt;/p&gt;

&lt;h4&gt;Динаміка середніх зарплат C++&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-dynamic-cplus"&gt;&lt;/div&gt;

&lt;p&gt;Найпопулярніша додаткова мова програмування — Python (40 анкет). Стільки ж респондентів сказали, що використовують лише основну мову — C++. Найвищі зарплати у тих, хто додатково працює ще і з Java — $3625.&lt;/p&gt;

&lt;h4&gt;Середні зарплати C++ розробників з розбивкою за фреймворками та додатковою мовою програмування&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-add-cplus"&gt;&lt;/div&gt;

&lt;h3&gt;Ruby/Rails&lt;/h3&gt;

&lt;p&gt;Середня зарплата Senior Ruby/Rails-розробників зросла на $300 за півроку, а Middle — на $225. Не змінилася зарплата у джуніорів.&lt;/p&gt;

&lt;h4&gt;Динаміка середніх зарплат Ruby/Rails&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-dynamic-ruby"&gt;&lt;/div&gt;

&lt;h4&gt;Середні зарплати Ruby-розробників з розбивкою за фреймворками та додатковою мовою програмування&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-add-ruby"&gt;&lt;/div&gt;

&lt;h3&gt;Swift&lt;/h3&gt;

&lt;p&gt;Усі категорії Swift-розробників демонструють негативну динаміку за останні півроку: якщо середня зарплата Software Engineer зменшилася на $50, то середня зарплата джуніорів і сеньорів на $175 і $100 відповідно. &lt;/p&gt;

&lt;h4&gt;Динаміка середніх зарплат Swift&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-dynamic-swift"&gt;&lt;/div&gt;

&lt;p&gt;Середня зарплата Swift-розробників, що додатково використовують Objective-C, майже в два рази вища, ніж у тих, хто використовує лише Swift.&lt;/p&gt;

&lt;h4&gt;Середні зарплати Swift-розробників з розбивкою за фреймворками та додатковою мовою програмування&lt;/h4&gt;

&lt;div class="chart-salary" id="chart-salary-add-swift"&gt;&lt;/div&gt;

&lt;p&gt;&lt;br&gt;Дані про кількість вакансій і відгуків дивіться в розділі &lt;a href="https://jobs.dou.ua/trends/" target="_blank"&gt;«Тренди»&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;em&gt;Візуалізація даних: &lt;a href="http://czrt.by/" target="_blank"&gt;Ігор Яновський&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;script src="https://d3js.org/d3.v5.min.js" type="text/javascript"&gt;&lt;/script&gt;&lt;link href="https://s.dou.ua/files/lenta/salary-report-devs-dec-2019/salary-2019-12.css?v4" rel="stylesheet" type="text/css"&gt;&lt;script src="https://s.dou.ua/files/lenta/salary-report-devs-dec-2019/salary-2019-12.js?v5" type="text/javascript"&gt;&lt;/script&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Редакція DOU</dc:creator><pubDate>Mon, 13 Jan 2020 10:01:15 +0200</pubDate><guid>https://dou.ua/lenta/articles/salary-report-devs-dec-2019/</guid></item><item><title>Разворачиваем AWS для разработки локально на базе LocalStack</title><link>https://dou.ua/lenta/articles/aws-localstack/</link><description>&lt;p&gt;Сейчас все больше компаний уходит в облака для запуска своих приложений. Мы в компании &lt;a href="https://www.namecheap.com/about/" target="_blank"&gt;Namecheap&lt;/a&gt; не стали исключением и уже довольно долго используем сервисы AWS. В связи с этим перед нами встала задача упростить работу с сервисами AWS в условиях локальной разработки. Как приблизить локальное окружение к условиям прода?&lt;/p&gt;

&lt;p&gt;В этой статье мы с вами поднимем небольшой проект, который будет взаимодействовать со стабами сервисов AWS, таких как: DynamoDB, SNS/SQS и S3.&lt;/p&gt;

&lt;p&gt;Одним из самых распространённых решений для стабов сервисов AWS является LocalStack. Ранее этот проект разрабатывался Atlassian, но теперь брошен в дикий open-source и монетизируется за поддержку ряда дополнительных сервисов и &lt;a href="https://localstack.cloud/#pricing"&gt;саппорт&lt;/a&gt;.&lt;/p&gt;

&lt;h4&gt;TL; DR&lt;/h4&gt;

&lt;ol&gt;&lt;li&gt;Поднимаем LocalStack при помощи docker-compose.&lt;/li&gt;&lt;li&gt;Переключаем проект на эндпоинт сервиса LocalStack.&lt;/li&gt;&lt;/ol&gt;

&lt;h2&gt;Холодный старт на Windows&lt;/h2&gt;

&lt;p&gt;Самый простой путь развернуть LocalStack локально — запустить его при помощи Docker Compose. &lt;/p&gt;

&lt;p&gt;Для начала нам нужно установить рабочую среду разработчика Docker for Windows. Установка и настройка этого инструмента выходит за пределы статьи, так что оставлю вам ссылочку на &lt;a href="https://docs.docker.com/docker-for-windows/install/" target="_blank"&gt;хороший официальный мануал&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;В содержимое docker-compose-файла запишем такой код:&lt;/p&gt;

&lt;pre&gt;version: '2.1'
services:
localstack:
image: localstack/localstack:latest
ports:
- "4567-4584:4567-4584"
- "8080:8080"
volumes:
- "//var/run/docker.sock:/var/run/docker.sock"
environment:
- SERVICES=dynamodb
- PORT_WEB_UI=8080
- DOCKER_HOST=unix:///var/run/docker.sock
&lt;/pre&gt;

&lt;p&gt;Осталось только поднять docker-compose-сервис:&lt;/p&gt;

&lt;pre&gt;docker-compose -f docker-compose.yml up -d localstack&lt;/pre&gt;

&lt;p&gt;Обратите внимание на установленную переменную окружения &lt;strong&gt;SERVICES&lt;/strong&gt;. С ее помощью сейчас включён сервис DynamoDB. Чтобы включить другие сервисы, настроить Debug-трейсы и кое-что ещё, настоятельно рекомендую &lt;a href="https://github.com/localstack/localstack#user-content-configurations" target="_blank"&gt;взглянуть в мануал&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Если у вас вылетает ошибка о занятом порте по типу такой, как описана ниже, можно убрать из файла порты неиспользуемых сервисов или перебиндить на другой порт.&lt;/p&gt;

&lt;pre&gt;docker: Error response from daemon: driver failed programming external connectivity on endpoint localstack_main (a156a7ce6d590937504c17b1f37f4634e7eaec09a9f8ba20cdf37b94424db39f): Error starting userland proxy: listen tcp 0.0.0.0:8080: bind: address already in use.&lt;/pre&gt;

&lt;p&gt;На одной из испытуемых систем это выглядело как-то так:&lt;/p&gt;

&lt;pre&gt;...
ports:
- "4567-4584:4567-4584"
- "9090:8080"
...
environment:
- PORT_WEB_UI=9090
...
&lt;/pre&gt;

&lt;p&gt;Можно попробовать запустить LocalStack, как по мануалу — &lt;strong&gt;localstack start —docker&lt;/strong&gt;. Но есть ряд минусов. Во-первых, вам придётся установить окружение Python, для того чтобы при помощи pip установить LocalStack. А во-вторых, вам понадобится либо установить докер, либо установить Java-окружение, для того чтобы заработали некоторые стабы сервисов.&lt;/p&gt;

&lt;h2&gt;Работа с DynamoDB&lt;/h2&gt;

&lt;p&gt;Итак, у нас уже запустился и работает LocalStack. Теперь мы можем проверить работоспособность и заодно подготовить сервисы, с которыми будем работать. Для настройки этих сервисов придётся использовать AWS CLI. Надеюсь, он уже у вас &lt;a href="https://docs.aws.amazon.com/cli/latest/userguide/install-windows.html" target="_blank"&gt;установлен&lt;/a&gt;. Для того, чтобы подключиться к нашим сервисам, нужно будет указать в конце команды кастомный эндпоинт при помощи следующего параметра &lt;strong&gt;—endpoint-url=http://localhost:4578&lt;/strong&gt;, где номер порта мы можем взять из таблицы официального мануала.&lt;/p&gt;

&lt;p&gt;Для начала проверим, что скажет LocalStack о состоянии таблиц:&lt;/p&gt;

&lt;pre&gt;aws dynamodb list-tables --endpoint-url=http://localhost:4569
{
    "TableNames": []
}
&lt;/pre&gt;

&lt;p&gt;После чего создадим таблицу:&lt;/p&gt;

&lt;pre&gt;aws dynamodb create-table --table-name Todo \
--key-schema AttributeName=Id,KeyType=HASH --attribute-definitions AttributeName=Id,AttributeType=N AttributeName=Name,AttributeType=S \
--provisioned-throughput ReadCapacityUnits=10,WriteCapacityUnits=5 --endpoint-url=http://localhost:4569 
&lt;/pre&gt;

&lt;p&gt;И ещё раз взглянем в lLocalStack на список. Он покажет только что созданную таблицу:&lt;/p&gt;

&lt;pre&gt;aws dynamodb list-tables --endpoint-url=http://localhost:4569
{
    "TableNames": [
        "Todo"
    ]
}
&lt;/pre&gt;

&lt;p&gt;Ну что же поздравляю, теперь у вас есть свой первый локальный сервис амазона.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;HINT:&lt;/strong&gt; Для тех, кому нужно сетапать инфраструкту не в ручном режиме, а с помощью терраформ, есть отличный механизм сделать это, задав маппинг ендпоинтов в модуле AWS:&lt;/p&gt;

&lt;pre&gt;provider "aws" {
    skip_credentials_validation = true
    skip_metadata_api_check = true
    s3_force_path_style = true
    access_key = "mock_access_key"
    secret_key = "mock_secret_key"
    endpoints {
        dynamodb = "http://localhost:4569"
    }
}
&lt;/pre&gt;

&lt;p&gt;Чуть больше инфы по этому вопросу можно взять&lt;a href="https://medium.com/@geekrodion/system-testing-localstack-terraforms-37b31ba99310" target="_blank"&gt; здесь&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Теперь давайте попробуем подключиться к DynamoDB из нашего тестового приложения. В любимой IDE создаём консольное dotnet core приложение. И сразу же устанавливаем пакет &lt;strong&gt;AWSSDK.DynamoDBv2&lt;/strong&gt;. Общие правила для большинства подключения к сервисам LocalStack:&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;Переключаемся на использование HTTP-протокола (LocalStack из коробки работает через HTTP,&lt;a href="https://github.com/localstack/localstack#user-content-a-note-about-using-custom-ssl-certificates-for-use_ssl1" target="_blank"&gt; хотя и поддерживает https&lt;/a&gt;).&lt;/li&gt;&lt;li&gt;Устанавливаем ServiceURL на порт этого стаба.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;Давайте настроим подключение:&lt;/p&gt;

&lt;pre&gt;var clientConfig = new AmazonDynamoDBConfig()
{
    UseHttp = true,
    ServiceURL = "http://localhost:4569"
};

_dynamoClient = new AmazonDynamoDBClient(clientConfig);&lt;/pre&gt;

&lt;p&gt;После этого мы можем положить в нашу таблицу первое значение:&lt;/p&gt;

&lt;pre&gt;var putItemRequest = new PutItemRequest()
{
    TableName = TableName,
    Item = 
    {
        {
            "Id", new AttributeValue() { N = "42"}
        },
        {
            "Name", new AttributeValue() {S = "Get Up Early"}
        }
    }
};
await _dynamoClient.PutItemAsync(putItemRequest);&lt;/pre&gt;

&lt;p&gt;Можем проверить, что же сохранилось в LocalStack следующей командой:&lt;/p&gt;

&lt;pre&gt;aws dynamodb get-item --table-name Todo --key '{"Id":{"N":"42"}}' --endpoint-url=http://localhost:4569
{
    "Item": {
        "Id": {
            "N": "42"
        },
        "Name": {
            "S": "Get Up Early"
        }
    }
}
&lt;/pre&gt;

&lt;h2&gt;Добавляем SNS &amp;amp; SQS&lt;/h2&gt;

&lt;p&gt;Представим, что теперь нам нужно добавить SNS и SQS. Начнём с SNS. Для начала включим сервис и создадим топик. Для этого в compose-файле добавим в переменную окружения SERVICES разделённые запятой имена сервисов, как это сделано ниже:&lt;/p&gt;

&lt;pre&gt;...
environment:
- SERVICES=dynamodb,sns,sqs,s3
...
&lt;/pre&gt;

&lt;p&gt;и перезапускаем его, чтобы подтянулись эти значения, следующей командой:&lt;/p&gt;

&lt;pre&gt;docker-compose -f docker-compose.yml restart localstack&lt;/pre&gt;

&lt;p&gt;В проект добавим nuget-пакеты &lt;strong&gt;AWSSDK.SimpleNotificationService&lt;/strong&gt; и &lt;strong&gt;AWSSDK.SimpleNotificationService&lt;/strong&gt;, для того чтобы получить возможность взаимодействовать с этими сервисами.&lt;/p&gt;

&lt;p&gt;Как и для предыдущего случая настраиваем подключения:&lt;/p&gt;

&lt;pre&gt;var snsConfig = new AmazonSimpleNotificationServiceConfig()
{
    UseHttp = true,
    ServiceURL = "http://localhost:4575"
};

snsClient = new AmazonSimpleNotificationServiceClient(snsConfig);

var sqsConfig = new AmazonSQSConfig()
{
    UseHttp = true,
    ServiceURL = "http://localhost:4576"
};

sqsClient = new AmazonSQSClient(sqsConfig);&lt;/pre&gt;

&lt;p&gt;Теперь мы можем работать с этими двумя сервисами локально. Давайте сразу же создадим очередь и топик и подпишемся очередью на него:&lt;/p&gt;

&lt;pre&gt;private void CreateQueue()
{
    var queueCreationResult = await sqsClient.CreateQueueAsync("MyQueue");
    var queueUrl = queueCreationResult.QueueUrl;
    var topicCreationResult = await snsClient.CreateTopicAsync(new  CreateTopicRequest("TopicName"));
    var topicArn = topicCreationResult.TopicArn;
    var subscribeRequest = new SubscribeRequest(topicArn, "sqs", queueUrl);
    var subscribeResponse = await snsClient.SubscribeAsync(subscribeRequest);
}
&lt;/pre&gt;

&lt;p&gt;В тестовых целях отправим в топик оповещение и вычитаем его из очереди:&lt;/p&gt;

&lt;pre&gt;...
// Publish message to topic
var request = new PublishRequest
{
    TopicArn = topicArn,
    Message = "Test Message"
};

await snsClient.PublishAsync(request);

...
// Read message from queue
var result = await sqsClient.ReceiveMessageAsync(queueUrl);
foreach (var message in result.Messages)
{
    Console.WriteLine(message.Body);
}
...
&lt;/pre&gt;

&lt;p&gt;В консоли мы видим следующее:&lt;/p&gt;

&lt;pre&gt;{"MessageId": "e4e6ef59-107a-479d-952d-2a9b9e2da15c", "Type": "Notification", "Timestamp": "2019-10-05T13:27:36.397Z", "Message": "hello", "TopicArn": "arn:aws:sns:eu-west-3:000000000000:test"}&lt;/pre&gt;

&lt;p&gt;Это говорит о том, что всё успешно работает.&lt;/p&gt;

&lt;h2&gt;Сервис S3&lt;/h2&gt;

&lt;p&gt;Давайте примемся за самый используемый сервис — S3. Так как ранее мы его уже включили, можем оставить compose-файл в покое.&lt;/p&gt;

&lt;p&gt;Устанавливаем nuget &lt;strong&gt;AWSSDK.S3&lt;/strong&gt; и создаём следующий конфиг для использования LocalStack-овского S3. Ничего нового — HTTP и кастомный порт, на котором крутится сервис:&lt;/p&gt;

&lt;pre&gt;var clientConfig = new AmazonS3Config()
{
    UseHttp = true,
    ServiceURL = "http://localhost:4572"
};
s3Client = new AmazonS3Client(clientConfig);
&lt;/pre&gt;

&lt;p&gt;Давайте посмотрим, как этот сервис работает. Для этого создадим ведёрко и зальём на него файл.&lt;/p&gt;

&lt;pre&gt;await s3Client.PutBucketAsync(BucketName);
var putRequest = new PutObjectRequest()
{
    BucketName = BucketName,
    Metadata = { ["x-amz-meta-title"] = "Title" },
    FilePath = Path.GetFileName(FileName),
    ContentType = "text/plain"
};
await s3Client.PutObjectAsync(putRequest);&lt;/pre&gt;

&lt;p&gt;Можем взглянуть на его содержимое:&lt;/p&gt;

&lt;pre&gt;var result = await s3Client.ListObjectsAsync(BucketName);
foreach (var s3Object in result.S3Objects)
{
    Console.WriteLine(s3Object.Key);
}
&lt;/pre&gt;

&lt;p&gt;Попробуем скачать:&lt;/p&gt;

&lt;pre&gt;using (GetObjectResponse response = await s3Client.GetObjectAsync(BucketName, FileName))
using (Stream responseStream = response.ResponseStream)
using (StreamReader reader = new StreamReader(responseStream))
{
    Console.WriteLine("Object metadata, Title: {0}", response.Metadata["x-amz-meta-title"]);
    Console.WriteLine("Content type: {0}", response.Headers["Content-Type"]);
    Console.WriteLine(reader.ReadToEnd());
}
&lt;/pre&gt;

&lt;p&gt;Осталось только подчистить за собой состояние сервиса:&lt;/p&gt;

&lt;pre&gt;await s3Client.DeleteObjectAsync(BucketName, FileName);
await s3Client.DeleteBucketAsync(BucketName);&lt;/pre&gt;

&lt;h2&gt;Выводы&lt;/h2&gt;

&lt;p&gt;Это всё! Вот так мы подключили приложение, настроили и поработали со стабами трёх сервисов AWS — DynamoDB, SNS/SQS и S3. Теперь, зная, как пользоваться этим инструментом, мы можем вести разработку приложения локально, а не реальный демо-аккаунт AWS. Это даёт нам возможность с самого начала разработки задать высокий уровень development experience. Всем, кому интересно чуть больше поиграться с LocalStack и попробовать взаимодействие с ним в тестовом проекте, &lt;a href="https://github.com/LVladymyr/AwsLocalstack" target="_blank"&gt;прошу в репозиторий&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Vladymyr Liashenko</dc:creator><pubDate>Fri, 10 Jan 2020 14:21:10 +0200</pubDate><guid>https://dou.ua/lenta/articles/aws-localstack/</guid></item></channel></rss>